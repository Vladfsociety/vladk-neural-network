{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9489d3dc-1b5a-41ff-bda3-3553d9a3963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.model.activation import Relu, LeakyRelu, Linear, Sigmoid\n",
    "from src.model.base import NeuralNetwork\n",
    "from src.model.layer import Convolutional3x3x16x0x1, Input3D, Input, FullyConnected, Flatten\n",
    "from src.model.loss import CategoricalCrossEntropy\n",
    "from src.model.metric import AccuracyOneHot\n",
    "from src.model.optimizer import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d08b65-bb36-4e2a-b4b9-a54c97d2210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.sizeInput3D(Layer)\n",
      "(1, 5, 5)\n",
      "previous_layer.size\n",
      "(1, 5, 5)\n",
      "size\n",
      "(2, 1, 2, 2)\n",
      "n_inputs\n",
      "4\n",
      "previous_layer.size\n",
      "(2, 4, 4)\n",
      "size\n",
      "(2, 2, 2, 2)\n",
      "n_inputs\n",
      "8\n",
      "previous_layer.size\n",
      "(2, 3, 3)\n",
      "previous_layer_size\n",
      "18\n",
      "[{'a': tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]]),\n",
      "  'type': 'input_3d'},\n",
      " {'a': tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]),\n",
      "  'activation_function': <src.model.activation.LeakyRelu object at 0x73bc3776baa0>,\n",
      "  'b': tensor([[0.],\n",
      "        [0.]]),\n",
      "  'filters_num': 2,\n",
      "  'input_c': 1,\n",
      "  'input_h': 5,\n",
      "  'input_w': 5,\n",
      "  'kernel': 2,\n",
      "  'learnable': True,\n",
      "  'output_c': 2,\n",
      "  'output_h': 4,\n",
      "  'output_w': 4,\n",
      "  'type': 'convolutional',\n",
      "  'w': tensor([[[[-0.1190, -0.2693],\n",
      "          [-0.3340,  0.4138]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0779,  0.1901],\n",
      "          [ 0.0531, -0.1165]]]]),\n",
      "  'w_shape': (2, 1, 2, 2),\n",
      "  'z': tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])},\n",
      " {'a': tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]]),\n",
      "  'activation_function': <src.model.activation.LeakyRelu object at 0x73bc3776bb00>,\n",
      "  'b': tensor([[0.],\n",
      "        [0.]]),\n",
      "  'filters_num': 2,\n",
      "  'input_c': 2,\n",
      "  'input_h': 4,\n",
      "  'input_w': 4,\n",
      "  'kernel': 2,\n",
      "  'learnable': True,\n",
      "  'output_c': 2,\n",
      "  'output_h': 3,\n",
      "  'output_w': 3,\n",
      "  'type': 'convolutional',\n",
      "  'w': tensor([[[[-0.0841, -0.1904],\n",
      "          [-0.2361,  0.2926]],\n",
      "\n",
      "         [[ 0.0551,  0.1344],\n",
      "          [ 0.0375, -0.0823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1638,  0.0540],\n",
      "          [ 0.1988,  0.1143]],\n",
      "\n",
      "         [[ 0.2399, -0.0429],\n",
      "          [-0.2439, -0.2476]]]]),\n",
      "  'w_shape': (2, 2, 2, 2),\n",
      "  'z': tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])},\n",
      " {'a': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]),\n",
      "  'b': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]),\n",
      "  'learnable': False,\n",
      "  'type': 'flatten',\n",
      "  'w': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]),\n",
      "  'z': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])},\n",
      " {'a': tensor([[0.],\n",
      "        [0.]]),\n",
      "  'activation_function': <src.model.activation.Linear object at 0x73bc3776bbc0>,\n",
      "  'b': tensor([[0.],\n",
      "        [0.]]),\n",
      "  'learnable': True,\n",
      "  'type': 'fully_connected',\n",
      "  'w': tensor([[ 0.3156, -0.4702,  0.2187,  0.1708, -0.6230,  0.4021, -0.6604,  0.5189,\n",
      "          0.4823, -0.4018,  0.3199,  0.3286, -0.5303,  0.2403, -0.5321,  0.5844,\n",
      "          0.2671,  0.6788],\n",
      "        [-0.6314, -0.2577,  0.1696,  0.1530, -0.4496,  0.5484,  0.4901, -0.2808,\n",
      "         -0.5008,  0.2371, -0.1313,  0.2310, -0.0095, -0.1487, -0.6765, -0.5163,\n",
      "         -0.0588,  0.3227]]),\n",
      "  'z': tensor([[0.],\n",
      "        [0.]])}]\n",
      "epoch_________________________________________\n",
      "1\n",
      "type(self.__layers[layer_index][\"z\"])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "type(self.__layers[layer_index][\"z\"])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "layer_error.shape_before_reshape\n",
      "torch.Size([18, 1])\n",
      "tensor([[-0.2329],\n",
      "        [ 0.4409],\n",
      "        [-0.2090],\n",
      "        [-0.1648],\n",
      "        [ 0.5926],\n",
      "        [-0.4027],\n",
      "        [ 0.5525],\n",
      "        [-0.4422],\n",
      "        [-0.3923],\n",
      "        [ 0.3409],\n",
      "        [-0.2760],\n",
      "        [-0.3121],\n",
      "        [ 0.4752],\n",
      "        [-0.2034],\n",
      "        [ 0.5291],\n",
      "        [-0.4824],\n",
      "        [-0.2343],\n",
      "        [-0.6326]])\n",
      "layer_error.shape_after_reshape\n",
      "tensor([[[-0.2329,  0.4409, -0.2090],\n",
      "         [-0.1648,  0.5926, -0.4027],\n",
      "         [ 0.5525, -0.4422, -0.3923]],\n",
      "\n",
      "        [[ 0.3409, -0.2760, -0.3121],\n",
      "         [ 0.4752, -0.2034,  0.5291],\n",
      "         [-0.4824, -0.2343, -0.6326]]])\n",
      "error\n",
      "torch.Size([2, 4, 4])\n",
      "f, i, j  0 0 0\n",
      "error[f][i][j]\n",
      "tensor(0.0002)\n",
      "f, i, j  0 0 1\n",
      "error[f][i][j]\n",
      "tensor(-0.0004)\n",
      "f, i, j  0 0 1\n",
      "error[f][i][j]\n",
      "tensor(7.2497e-05)\n",
      "f, i, j  0 0 2\n",
      "error[f][i][j]\n",
      "tensor(0.0002)\n",
      "f, i, j  0 0 2\n",
      "error[f][i][j]\n",
      "tensor(-0.0007)\n",
      "f, i, j  0 0 3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     75\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec time: \u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_111\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/vladk-neural-network/src/model/base.py:455\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, train_dataset, test_dataset, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m    449\u001b[0m batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    450\u001b[0m     train_dataset[k : k \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_dataset), batch_size)\n\u001b[1;32m    452\u001b[0m ]\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__prediction)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__actual \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__actual)\n",
      "File \u001b[0;32m~/Documents/Projects/vladk-neural-network/src/model/base.py:420\u001b[0m, in \u001b[0;36mNeuralNetwork.__process_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    416\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__actual\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m--> 420\u001b[0m grads_w_update, grads_b_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m grads_w \u001b[38;5;241m=\u001b[39m [value \u001b[38;5;241m+\u001b[39m update \u001b[38;5;28;01mfor\u001b[39;00m value, update \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grads_w, grads_w_update)]\n\u001b[1;32m    423\u001b[0m grads_b \u001b[38;5;241m=\u001b[39m [value \u001b[38;5;241m+\u001b[39m update \u001b[38;5;28;01mfor\u001b[39;00m value, update \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grads_b, grads_b_update)]\n",
      "File \u001b[0;32m~/Documents/Projects/vladk-neural-network/src/model/base.py:249\u001b[0m, in \u001b[0;36mNeuralNetwork.__backward\u001b[0;34m(self, predict, actual)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m-\u001b[39m ii \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (j \u001b[38;5;241m-\u001b[39m jj \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf, i, j \u001b[39m\u001b[38;5;124m'\u001b[39m, f, i, j)\n\u001b[0;32m--> 249\u001b[0m     error[f][i][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mlayer_error\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf_next\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    250\u001b[0m            \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__layers[layer_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m][f_next][f][ii][jj]\n\u001b[1;32m    251\u001b[0m            \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__layers[layer_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_function\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mderivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__layers[layer_index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m][f][i][j]))\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror[f][i][j]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mprint\u001b[39m(error[f][i][j])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "train_data = [\n",
    "    {\n",
    "        'input': [\n",
    "            [\n",
    "                [0.0, 1.0, 1.0, 1.0, 0.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [0.0, 1.0, 1.0, 1.0, 0.0],\n",
    "            ]\n",
    "        ],\n",
    "        'output': [1.0, 0.0]\n",
    "    },\n",
    "    {\n",
    "        'input': [\n",
    "            [\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        ],\n",
    "        'output': [0.0, 1.0]\n",
    "    }    \n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        'input': [\n",
    "            [\n",
    "                [1.0, 0.0, 1.0, 1.0, 0.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                [0.0, 1.0, 1.0, 1.0, 0.0],\n",
    "            ]\n",
    "        ],\n",
    "        'output': [1.0, 0.0]\n",
    "    },\n",
    "    {\n",
    "        'input': [\n",
    "            [\n",
    "                [0.0, 1.0, 0.0, 0.0, 1.0],\n",
    "                [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                [1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        ],\n",
    "        'output': [0.0, 1.0]\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "layers = [\n",
    "    Convolutional3x3x16x0x1(LeakyRelu()),\n",
    "    Convolutional3x3x16x0x1(LeakyRelu()),\n",
    "    Flatten(),\n",
    "    #FullyConnected(10, LeakyRelu()),\n",
    "    FullyConnected(2, Linear())\n",
    "]\n",
    "nn = NeuralNetwork(\n",
    "    Input3D((1, 5, 5)),\n",
    "    layers,\n",
    "    optimizer=SGD(),\n",
    "    loss=CategoricalCrossEntropy(),\n",
    "    metric=AccuracyOneHot(),\n",
    "    convert_prediction='argmax'\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "epochs = 10\n",
    "nn.fit(train_data, test_data, epochs=epochs, verbose=True)\n",
    "print('exec time: ', time.time() - start_time)\n",
    "\n",
    "print('test_111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae876ade-c60d-4799-967d-ad3e847b8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = [\n",
    "#     {\n",
    "#         'input': [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0],\n",
    "#         'output': [1.0, 0.0]\n",
    "#     },\n",
    "#     {\n",
    "#         'input': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "#         'output': [0.0, 1.0]\n",
    "#     }    \n",
    "# ]\n",
    "\n",
    "# test_data = [\n",
    "#     {\n",
    "#         'input': [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0],\n",
    "#         'output': [1.0, 0.0]\n",
    "#     },\n",
    "#     {\n",
    "#         'input': [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
    "#         'output': [0.0, 1.0]\n",
    "#     }    \n",
    "# ]\n",
    "\n",
    "# layers = [\n",
    "#     FullyConnected(25, LeakyRelu()),\n",
    "#     FullyConnected(10, LeakyRelu()),\n",
    "#     FullyConnected(2, Linear())\n",
    "# ]\n",
    "# nn = NeuralNetwork(\n",
    "#     Input(25),\n",
    "#     layers,\n",
    "#     optimizer=SGD(),\n",
    "#     loss=CategoricalCrossEntropy(),\n",
    "#     metric=AccuracyOneHot(),\n",
    "#     convert_prediction='argmax'\n",
    "# )\n",
    "\n",
    "# start_time = time.time()\n",
    "# epochs = 200\n",
    "# nn.fit(train_data, test_data, epochs=epochs, verbose=True)\n",
    "# print('exec time: ', time.time() - start_time)\n",
    "\n",
    "# print('test_222')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
