[tool.poetry]
name = "vladk-neural-network"
version = "0.1.0"
description = "A description of your project"
authors = ["Your Name <you@example.com>"]

[tool.poetry.dependencies]
python = "^3.8"
# Add other dependencies here

[tool.poetry.packages]
include = ["vladk_neural_network"]


test_predictions
[[tensor([0.0133])], [tensor([3.4210])], [tensor([1.7721])]]

test_predictions
[[tensor([-0.0902])], [tensor([2.8185])], [tensor([1.4110])]]


[[tensor([-0.2594])], [tensor([1.7169])], [tensor([0.7606])]]


[[tensor([-0.2912])], [tensor([1.2591])], [tensor([0.5090])]]

[[tensor([-0.1964])],
 [tensor([1.0806])],
 [tensor([0.4627])],
 [tensor([0.6686])]]

 [[tensor([-0.0863])],
 [tensor([1.0168])],
 [tensor([0.4830])],
 [tensor([0.6609])]]

 [[tensor([-0.0070])],
 [tensor([0.9716])],
 [tensor([0.4981])],
 [tensor([0.6560])]]


  /home/vlad/Documents/Projects/vladk-neural-network/src/main.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()
/home/vlad/Documents/Projects/vladk-neural-network/src/model/base.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.loss.backward(self.optimizer, self._layers, torch.tensor(predict), torch.tensor(train_sample['output']))
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y = torch.tensor(y)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  z = torch.tensor(z)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:72: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y = torch.tensor(y)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  z = torch.tensor(z)
/home/vlad/Documents/Projects/vladk-neural-network/src/main.py:72: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()




  if no use output layer
  poetry run python src/main.py > output.txt
/home/vlad/Documents/Projects/vladk-neural-network/src/model/base.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.loss.backward(self.optimizer, self._layers, torch.tensor(predict), torch.tensor(train_sample['output']))
Traceback (most recent call last):
  File "/home/vlad/Documents/Projects/vladk-neural-network/src/main.py", line 188, in <module>
    nn.fit(train_dataset, test_dataset, epochs=epochs)
  File "/home/vlad/Documents/Projects/vladk-neural-network/src/model/base.py", line 95, in fit
    loss = self.loss.calculate(torch.tensor(self._prediction), torch.tensor(self._actual))
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: only one element tensors can be converted to Python scalars


Первым делом добавить тесты





batch 1 
Epoch: 49/50, Loss: 0.0113, r2 score: 0.9987
Test dataset validation. Loss: 0.0139, r2 score: 0.9984
--- 16.43903636932373 seconds ---


batch 2
Epoch: 49/50, Loss: 0.1676, r2 score: 0.9803
Test dataset validation. Loss: 0.1775, r2 score: 0.9801
--- 16.935725212097168 seconds ---

batch 1
Epoch: 49/50, Loss: 0.0095, r2 score: 0.9989
Test dataset validation. Loss: 0.0114, r2 score: 0.9987
--- 16.717719554901123 seconds ---

batch 4
Epoch: 49/50, Loss: 5.8183, r2 score: 0.3156
Test dataset validation. Loss: 5.9799, r2 score: 0.3287
--- 18.0739266872406 seconds ---

batch 4 lr 0.01
Epoch: 49/50, Loss: 0.0004, r2 score: 1.0
Test dataset validation. Loss: 0.0005, r2 score: 0.9999
--- 17.332524061203003 seconds ---

batch 1 lr 0.01
Epoch: 49/50, Loss: 0.001, r2 score: 0.9999
Test dataset validation. Loss: 0.0062, r2 score: 0.9993
--- 15.673651456832886 seconds ---


more complic model
batch 1
Epoch: 99/100, Loss: 0.4454, r2 score: 0.9908
Test dataset validation. Loss: 0.7514, r2 score: 0.9854
--- 3.9565186500549316 seconds ---


batch 4
Epoch: 99/100, Loss: 1.1448, r2 score: 0.9764
Test dataset validation. Loss: 1.313, r2 score: 0.9745
--- 3.285139322280884 seconds ---

batch 8
Epoch: 99/100, Loss: 1.3276, r2 score: 0.9726
Test dataset validation. Loss: 1.424, r2 score: 0.9723
--- 3.2789177894592285 seconds ---

batch 16
Epoch: 99/100, Loss: 2.0787, r2 score: 0.9571
Test dataset validation. Loss: 2.0876, r2 score: 0.9594
--- 3.0714268684387207 seconds ---


3d quad
batch 1
Epoch: 19/20, Loss: 0.0006, r2 score: 0.9999
Test dataset validation. Loss: 0.1335, r2 score: 0.9736
--- 423.70688581466675 seconds ---

batch 32
Epoch: 20/20, Loss: 0.0146, r2 score: 0.9969
Test dataset validation. Loss: 0.0601, r2 score: 0.9881
--- 156.04590106010437 seconds ---

batch 64
Epoch: 20/20, Loss: 0.0275, r2 score: 0.9941
Test dataset validation. Loss: 0.0635, r2 score: 0.9875
--- 138.64127945899963 seconds ---

batch 128
Epoch: 20/20, Loss: 0.0824, r2 score: 0.9822
Test dataset validation. Loss: 0.1834, r2 score: 0.9638
--- 153.09762501716614 seconds ---

batch 256
Epoch: 20/20, Loss: 1.0324, r2 score: 0.7767
Test dataset validation. Loss: 1.2249, r2 score: 0.758
--- 144.80464816093445 seconds ---

batch 64
Epoch: 20/20, Loss: 0.032, r2 score: 0.9931
Test dataset validation. Loss: 0.0784, r2 score: 0.9845
--- 148.19429850578308 seconds ---

batch 64 shuffle
Epoch: 20/20, Loss: 0.0283, r2 score: 0.9939
Test dataset validation. Loss: 0.0329, r2 score: 0.9935
--- 156.4179859161377 seconds --







Epoch: 40/40, Loss: 0.5841, R2 score: 0.9759
Test dataset validation. Loss: 0.6434, R2 score: 0.975
--- 16.375547409057617 seconds ---


Epoch: 40/40, Loss: 0.5669, R2 score: 0.9766
Test dataset validation. Loss: 0.6277, R2 score: 0.9756
--- 14.545613050460815 seconds ---


'b': tensor([[ 0.3932],
        [ 0.2622],
        [-0.1065],
        [ 0.1861],
        [ 0.4144],
        [ 0.2395],
        [-0.5613],
        [ 0.1152],
        [-0.1406],
        [ 0.4850],
        [-0.5589],
        [ 0.5319],
        [ 0.3562],
        [-0.1339],
        [ 0.2887],
        [-0.3296]]),

'w': tensor([[-0.1276, -0.2779,  0.4979,  0.5601,  0.2960, -0.2253,  0.2908,  0.1090,
          0.4300, -0.0269,  0.3568, -0.3834, -0.0432,  0.3246, -0.4088,  0.5653]]),



'b': tensor([[ 0.4043],
        [ 0.3085],
        [-0.1065],
        [ 0.1836],
        [ 0.3595],
        [ 0.1364],
        [-0.5613],
        [ 0.1327],
        [-0.1406],
        [ 0.4958],
        [-0.5589],
        [ 0.4930],
        [ 0.3183],
        [-0.1339],
        [ 0.2830],
        [-0.3296]])

'w': tensor([[-0.1167, -0.2779,  0.4979,  0.6723,  0.2960, -0.2881,  0.2908,  0.1792,
          0.4300, -0.0454,  0.3364, -0.3834, -0.0432,  0.3246, -0.4088,  0.6313]]),


Похоже что стоит попробовать с leaky relu







Так на ирисе воспроизводится хороший но не идеальній результат
layers = [
    FullyConnected(4, Relu()),
    FullyConnected(1, Sigmoid())
]
nn = NeuralNetwork(
    Input(4),
    layers,
    optimizer=SGD(learning_rate=0.001),
    loss=BinaryCrossEntropy(),
    metric=Accuracy(),
    convert_prediction='binary'
)

epochs = 30
nn.fit(train_dataset, test_dataset, epochs=epochs, batch_size=1, verbose=True)



















============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-8.3.2, pluggy-1.5.0
rootdir: /home/vlad/Documents/Projects/vladk-neural-network
configfile: pyproject.toml
testpaths: tests
collected 9 items

tests/test_binary_classification.py 
Binary classification. Testing Iris-setosa - Iris-versicolor combination
Epoch: 1/50, Loss: 0.66, Accuracy: 0.5857
Epoch: 2/50, Loss: 0.6436, Accuracy: 0.5857
Epoch: 3/50, Loss: 0.63, Accuracy: 0.5857
Epoch: 4/50, Loss: 0.6182, Accuracy: 0.5857
Epoch: 5/50, Loss: 0.6062, Accuracy: 0.5857
Epoch: 6/50, Loss: 0.5933, Accuracy: 0.5857
Epoch: 7/50, Loss: 0.5797, Accuracy: 0.5857
Epoch: 8/50, Loss: 0.5651, Accuracy: 0.5857
Epoch: 9/50, Loss: 0.5498, Accuracy: 0.5857
Epoch: 10/50, Loss: 0.5336, Accuracy: 0.5857
Epoch: 11/50, Loss: 0.5162, Accuracy: 0.7714
Epoch: 12/50, Loss: 0.4976, Accuracy: 0.7286
Epoch: 13/50, Loss: 0.478, Accuracy: 0.9571
Epoch: 14/50, Loss: 0.4571, Accuracy: 0.9714
Epoch: 15/50, Loss: 0.4345, Accuracy: 1.0
Epoch: 16/50, Loss: 0.4117, Accuracy: 1.0
Epoch: 17/50, Loss: 0.3879, Accuracy: 1.0
Epoch: 18/50, Loss: 0.3641, Accuracy: 1.0
Epoch: 19/50, Loss: 0.34, Accuracy: 1.0
Epoch: 20/50, Loss: 0.3161, Accuracy: 1.0
Epoch: 21/50, Loss: 0.2922, Accuracy: 1.0
Epoch: 22/50, Loss: 0.2698, Accuracy: 1.0
Epoch: 23/50, Loss: 0.2479, Accuracy: 1.0
Epoch: 24/50, Loss: 0.2274, Accuracy: 1.0
Epoch: 25/50, Loss: 0.208, Accuracy: 1.0
Epoch: 26/50, Loss: 0.1905, Accuracy: 1.0
Epoch: 27/50, Loss: 0.1742, Accuracy: 1.0
Epoch: 28/50, Loss: 0.1592, Accuracy: 1.0
Epoch: 29/50, Loss: 0.1458, Accuracy: 1.0
Epoch: 30/50, Loss: 0.1335, Accuracy: 1.0
Epoch: 31/50, Loss: 0.1225, Accuracy: 1.0
Epoch: 32/50, Loss: 0.1125, Accuracy: 1.0
Epoch: 33/50, Loss: 0.1035, Accuracy: 1.0
Epoch: 34/50, Loss: 0.0954, Accuracy: 1.0
Epoch: 35/50, Loss: 0.0881, Accuracy: 1.0
Epoch: 36/50, Loss: 0.0815, Accuracy: 1.0
Epoch: 37/50, Loss: 0.0756, Accuracy: 1.0
Epoch: 38/50, Loss: 0.0703, Accuracy: 1.0
Epoch: 39/50, Loss: 0.0654, Accuracy: 1.0
Epoch: 40/50, Loss: 0.0611, Accuracy: 1.0
Epoch: 41/50, Loss: 0.0572, Accuracy: 1.0
Epoch: 42/50, Loss: 0.0536, Accuracy: 1.0
Epoch: 43/50, Loss: 0.0504, Accuracy: 1.0
Epoch: 44/50, Loss: 0.0474, Accuracy: 1.0
Epoch: 45/50, Loss: 0.0447, Accuracy: 1.0
Epoch: 46/50, Loss: 0.0422, Accuracy: 1.0
Epoch: 47/50, Loss: 0.0399, Accuracy: 1.0
Epoch: 48/50, Loss: 0.0378, Accuracy: 1.0
Epoch: 49/50, Loss: 0.0359, Accuracy: 1.0
Epoch: 50/50, Loss: 0.0341, Accuracy: 1.0
BCE: 0.04, Accuracy: 1.0, Fit time: 1.229 seconds
.
Binary classification. Testing Iris-versicolor - Iris-virginica combination
Epoch: 1/50, Loss: 0.6893, Accuracy: 0.4714
Epoch: 2/50, Loss: 0.6693, Accuracy: 0.7857
Epoch: 3/50, Loss: 0.6553, Accuracy: 0.7
Epoch: 4/50, Loss: 0.6437, Accuracy: 0.7143
Epoch: 5/50, Loss: 0.6349, Accuracy: 0.5857
Epoch: 6/50, Loss: 0.6271, Accuracy: 0.6
Epoch: 7/50, Loss: 0.6199, Accuracy: 0.5857
Epoch: 8/50, Loss: 0.6129, Accuracy: 0.6
Epoch: 9/50, Loss: 0.6062, Accuracy: 0.6286
Epoch: 10/50, Loss: 0.5992, Accuracy: 0.6857
Epoch: 11/50, Loss: 0.592, Accuracy: 0.6857
Epoch: 12/50, Loss: 0.5844, Accuracy: 0.6429
Epoch: 13/50, Loss: 0.5773, Accuracy: 0.7714
Epoch: 14/50, Loss: 0.5697, Accuracy: 0.7429
Epoch: 15/50, Loss: 0.5618, Accuracy: 0.7571
Epoch: 16/50, Loss: 0.5537, Accuracy: 0.7571
Epoch: 17/50, Loss: 0.5454, Accuracy: 0.8
Epoch: 18/50, Loss: 0.5367, Accuracy: 0.8143
Epoch: 19/50, Loss: 0.5278, Accuracy: 0.8143
Epoch: 20/50, Loss: 0.5189, Accuracy: 0.8143
Epoch: 21/50, Loss: 0.5095, Accuracy: 0.8286
Epoch: 22/50, Loss: 0.4997, Accuracy: 0.8857
Epoch: 23/50, Loss: 0.4898, Accuracy: 0.8571
Epoch: 24/50, Loss: 0.4802, Accuracy: 0.8714
Epoch: 25/50, Loss: 0.4697, Accuracy: 0.8857
Epoch: 26/50, Loss: 0.4595, Accuracy: 0.8857
Epoch: 27/50, Loss: 0.4497, Accuracy: 0.8714
Epoch: 28/50, Loss: 0.4392, Accuracy: 0.8857
Epoch: 29/50, Loss: 0.429, Accuracy: 0.8857
Epoch: 30/50, Loss: 0.418, Accuracy: 0.9
Epoch: 31/50, Loss: 0.4078, Accuracy: 0.9
Epoch: 32/50, Loss: 0.398, Accuracy: 0.9
Epoch: 33/50, Loss: 0.3877, Accuracy: 0.9143
Epoch: 34/50, Loss: 0.3775, Accuracy: 0.9
Epoch: 35/50, Loss: 0.3676, Accuracy: 0.9286
Epoch: 36/50, Loss: 0.357, Accuracy: 0.9143
Epoch: 37/50, Loss: 0.346, Accuracy: 0.9143
Epoch: 38/50, Loss: 0.3384, Accuracy: 0.9286
Epoch: 39/50, Loss: 0.3289, Accuracy: 0.9286
Epoch: 40/50, Loss: 0.3189, Accuracy: 0.9286
Epoch: 41/50, Loss: 0.3112, Accuracy: 0.9143
Epoch: 42/50, Loss: 0.3023, Accuracy: 0.9143
Epoch: 43/50, Loss: 0.2942, Accuracy: 0.9286
Epoch: 44/50, Loss: 0.2851, Accuracy: 0.9286
Epoch: 45/50, Loss: 0.2788, Accuracy: 0.9286
Epoch: 46/50, Loss: 0.2703, Accuracy: 0.9286
Epoch: 47/50, Loss: 0.2645, Accuracy: 0.9286
Epoch: 48/50, Loss: 0.2577, Accuracy: 0.9286
Epoch: 49/50, Loss: 0.2502, Accuracy: 0.9429
Epoch: 50/50, Loss: 0.2455, Accuracy: 0.9286
BCE: 0.227, Accuracy: 0.9333, Fit time: 1.2268 seconds
.
Binary classification. Testing Iris-setosa - Iris-virginica combination
Epoch: 1/50, Loss: 0.7856, Accuracy: 0.5
Epoch: 2/50, Loss: 0.706, Accuracy: 0.5
Epoch: 3/50, Loss: 0.6445, Accuracy: 0.5
Epoch: 4/50, Loss: 0.5955, Accuracy: 0.5857
Epoch: 5/50, Loss: 0.5551, Accuracy: 0.9286
Epoch: 6/50, Loss: 0.5213, Accuracy: 0.9857
Epoch: 7/50, Loss: 0.4914, Accuracy: 1.0
Epoch: 8/50, Loss: 0.4636, Accuracy: 1.0
Epoch: 9/50, Loss: 0.4359, Accuracy: 1.0
Epoch: 10/50, Loss: 0.4092, Accuracy: 1.0
Epoch: 11/50, Loss: 0.3826, Accuracy: 1.0
Epoch: 12/50, Loss: 0.3562, Accuracy: 1.0
Epoch: 13/50, Loss: 0.3305, Accuracy: 1.0
Epoch: 14/50, Loss: 0.3054, Accuracy: 1.0
Epoch: 15/50, Loss: 0.2813, Accuracy: 1.0
Epoch: 16/50, Loss: 0.2582, Accuracy: 1.0
Epoch: 17/50, Loss: 0.2369, Accuracy: 1.0
Epoch: 18/50, Loss: 0.2168, Accuracy: 1.0
Epoch: 19/50, Loss: 0.199, Accuracy: 1.0
Epoch: 20/50, Loss: 0.1825, Accuracy: 1.0
Epoch: 21/50, Loss: 0.1676, Accuracy: 1.0
Epoch: 22/50, Loss: 0.1539, Accuracy: 1.0
Epoch: 23/50, Loss: 0.1415, Accuracy: 1.0
Epoch: 24/50, Loss: 0.1303, Accuracy: 1.0
Epoch: 25/50, Loss: 0.1201, Accuracy: 1.0
Epoch: 26/50, Loss: 0.1108, Accuracy: 1.0
Epoch: 27/50, Loss: 0.1025, Accuracy: 1.0
Epoch: 28/50, Loss: 0.095, Accuracy: 1.0
Epoch: 29/50, Loss: 0.0883, Accuracy: 1.0
Epoch: 30/50, Loss: 0.0822, Accuracy: 1.0
Epoch: 31/50, Loss: 0.0768, Accuracy: 1.0
Epoch: 32/50, Loss: 0.0719, Accuracy: 1.0
Epoch: 33/50, Loss: 0.0674, Accuracy: 1.0
Epoch: 34/50, Loss: 0.0634, Accuracy: 1.0
Epoch: 35/50, Loss: 0.0598, Accuracy: 1.0
Epoch: 36/50, Loss: 0.0564, Accuracy: 1.0
Epoch: 37/50, Loss: 0.0533, Accuracy: 1.0
Epoch: 38/50, Loss: 0.0505, Accuracy: 1.0
Epoch: 39/50, Loss: 0.0479, Accuracy: 1.0
Epoch: 40/50, Loss: 0.0455, Accuracy: 1.0
Epoch: 41/50, Loss: 0.0433, Accuracy: 1.0
Epoch: 42/50, Loss: 0.0413, Accuracy: 1.0
Epoch: 43/50, Loss: 0.0394, Accuracy: 1.0
Epoch: 44/50, Loss: 0.0376, Accuracy: 1.0
Epoch: 45/50, Loss: 0.036, Accuracy: 1.0
Epoch: 46/50, Loss: 0.0345, Accuracy: 1.0
Epoch: 47/50, Loss: 0.0331, Accuracy: 1.0
Epoch: 48/50, Loss: 0.0318, Accuracy: 1.0
Epoch: 49/50, Loss: 0.0306, Accuracy: 1.0
Epoch: 50/50, Loss: 0.0295, Accuracy: 1.0
BCE: 0.0258, Accuracy: 1.0, Fit time: 1.2503 seconds
.
tests/test_multi_classification.py 
Multi classification. Testing on full iris dataset (3 species)
Epoch: 1/50, Loss: 1.0811, Accuracy: 0.4696
Epoch: 2/50, Loss: 0.9458, Accuracy: 0.7652
Epoch: 3/50, Loss: 0.8733, Accuracy: 0.7913
Epoch: 4/50, Loss: 0.8314, Accuracy: 0.8174
Epoch: 5/50, Loss: 0.8123, Accuracy: 0.8435
Epoch: 6/50, Loss: 0.7945, Accuracy: 0.8696
Epoch: 7/50, Loss: 0.781, Accuracy: 0.8957
Epoch: 8/50, Loss: 0.7641, Accuracy: 0.8522
Epoch: 9/50, Loss: 0.7515, Accuracy: 0.913
Epoch: 10/50, Loss: 0.7282, Accuracy: 0.9304
Epoch: 11/50, Loss: 0.7218, Accuracy: 0.8957
Epoch: 12/50, Loss: 0.6988, Accuracy: 0.9304
Epoch: 13/50, Loss: 0.6999, Accuracy: 0.9304
Epoch: 14/50, Loss: 0.6817, Accuracy: 0.9304
Epoch: 15/50, Loss: 0.6708, Accuracy: 0.9304
Epoch: 16/50, Loss: 0.6584, Accuracy: 0.9391
Epoch: 17/50, Loss: 0.6556, Accuracy: 0.9565
Epoch: 18/50, Loss: 0.6536, Accuracy: 0.9565
Epoch: 19/50, Loss: 0.6364, Accuracy: 0.9652
Epoch: 20/50, Loss: 0.6427, Accuracy: 0.9304
Epoch: 21/50, Loss: 0.6343, Accuracy: 0.9478
Epoch: 22/50, Loss: 0.6346, Accuracy: 0.9391
Epoch: 23/50, Loss: 0.6208, Accuracy: 0.9739
Epoch: 24/50, Loss: 0.632, Accuracy: 0.9565
Epoch: 25/50, Loss: 0.6235, Accuracy: 0.9652
Epoch: 26/50, Loss: 0.6245, Accuracy: 0.9391
Epoch: 27/50, Loss: 0.6263, Accuracy: 0.9565
Epoch: 28/50, Loss: 0.6295, Accuracy: 0.9565
Epoch: 29/50, Loss: 0.6208, Accuracy: 0.9565
Epoch: 30/50, Loss: 0.6159, Accuracy: 0.9652
Epoch: 31/50, Loss: 0.6089, Accuracy: 0.9565
Epoch: 32/50, Loss: 0.6178, Accuracy: 0.9391
Epoch: 33/50, Loss: 0.6151, Accuracy: 0.9739
Epoch: 34/50, Loss: 0.6107, Accuracy: 0.9478
Epoch: 35/50, Loss: 0.6171, Accuracy: 0.9565
Epoch: 36/50, Loss: 0.6154, Accuracy: 0.9826
Epoch: 37/50, Loss: 0.5973, Accuracy: 0.9652
Epoch: 38/50, Loss: 0.609, Accuracy: 0.9652
Epoch: 39/50, Loss: 0.611, Accuracy: 0.9652
Epoch: 40/50, Loss: 0.6131, Accuracy: 0.9565
Epoch: 41/50, Loss: 0.6109, Accuracy: 0.9478
Epoch: 42/50, Loss: 0.6118, Accuracy: 0.9652
Epoch: 43/50, Loss: 0.5991, Accuracy: 0.9826
Epoch: 44/50, Loss: 0.6151, Accuracy: 0.9478
Epoch: 45/50, Loss: 0.6053, Accuracy: 0.9652
Epoch: 46/50, Loss: 0.61, Accuracy: 0.9826
Epoch: 47/50, Loss: 0.6005, Accuracy: 0.9739
Epoch: 48/50, Loss: 0.6041, Accuracy: 0.9739
Epoch: 49/50, Loss: 0.606, Accuracy: 0.9565
Epoch: 50/50, Loss: 0.6021, Accuracy: 0.9739
CCE: 0.5783, Accuracy: 1.0, Fit time: 1.7031 seconds
.
Multi classification. Testing on digits dataset
Epoch: 1/20, Loss: 2.1376, Accuracy: 0.4805
Epoch: 2/20, Loss: 1.9571, Accuracy: 0.7755
Epoch: 3/20, Loss: 1.8708, Accuracy: 0.8455
Epoch: 4/20, Loss: 1.8127, Accuracy: 0.876
Epoch: 5/20, Loss: 1.7691, Accuracy: 0.9065
Epoch: 6/20, Loss: 1.7397, Accuracy: 0.9175
Epoch: 7/20, Loss: 1.7161, Accuracy: 0.927
Epoch: 8/20, Loss: 1.6956, Accuracy: 0.933
Epoch: 9/20, Loss: 1.6828, Accuracy: 0.9395
Epoch: 10/20, Loss: 1.6669, Accuracy: 0.947
Epoch: 11/20, Loss: 1.6558, Accuracy: 0.9525
Epoch: 12/20, Loss: 1.6447, Accuracy: 0.956
Epoch: 13/20, Loss: 1.6376, Accuracy: 0.9595
Epoch: 14/20, Loss: 1.627, Accuracy: 0.966
Epoch: 15/20, Loss: 1.6204, Accuracy: 0.9675
Epoch: 16/20, Loss: 1.6139, Accuracy: 0.97
Epoch: 17/20, Loss: 1.6074, Accuracy: 0.972
Epoch: 18/20, Loss: 1.602, Accuracy: 0.974
Epoch: 19/20, Loss: 1.5966, Accuracy: 0.979
Epoch: 20/20, Loss: 1.5904, Accuracy: 0.979
CCE: 1.6406, Accuracy: 0.92, Fit time: 21.6939 seconds
.
tests/test_regression.py 
Regression. Testing func_quadratic
Epoch: 1/50, Loss: 13.5262, R2 score: 0.4417
Epoch: 2/50, Loss: 1.6751, R2 score: 0.9309
Epoch: 3/50, Loss: 1.0717, R2 score: 0.9558
Epoch: 4/50, Loss: 0.9152, R2 score: 0.9622
Epoch: 5/50, Loss: 0.7106, R2 score: 0.9707
Epoch: 6/50, Loss: 0.6319, R2 score: 0.9739
Epoch: 7/50, Loss: 0.506, R2 score: 0.9791
Epoch: 8/50, Loss: 0.4816, R2 score: 0.9801
Epoch: 9/50, Loss: 0.4381, R2 score: 0.9819
Epoch: 10/50, Loss: 0.4551, R2 score: 0.9812
Epoch: 11/50, Loss: 0.4259, R2 score: 0.9824
Epoch: 12/50, Loss: 0.3389, R2 score: 0.986
Epoch: 13/50, Loss: 0.3156, R2 score: 0.987
Epoch: 14/50, Loss: 0.3511, R2 score: 0.9855
Epoch: 15/50, Loss: 0.304, R2 score: 0.9875
Epoch: 16/50, Loss: 0.3121, R2 score: 0.9871
Epoch: 17/50, Loss: 0.2912, R2 score: 0.988
Epoch: 18/50, Loss: 0.2782, R2 score: 0.9885
Epoch: 19/50, Loss: 0.2485, R2 score: 0.9897
Epoch: 20/50, Loss: 0.2531, R2 score: 0.9896
Epoch: 21/50, Loss: 0.2252, R2 score: 0.9907
Epoch: 22/50, Loss: 0.2079, R2 score: 0.9914
Epoch: 23/50, Loss: 0.1449, R2 score: 0.994
Epoch: 24/50, Loss: 0.2041, R2 score: 0.9916
Epoch: 25/50, Loss: 0.1776, R2 score: 0.9927
Epoch: 26/50, Loss: 0.1755, R2 score: 0.9928
Epoch: 27/50, Loss: 0.169, R2 score: 0.993
Epoch: 28/50, Loss: 0.1496, R2 score: 0.9938
Epoch: 29/50, Loss: 0.1343, R2 score: 0.9945
Epoch: 30/50, Loss: 0.1523, R2 score: 0.9937
Epoch: 31/50, Loss: 0.1313, R2 score: 0.9946
Epoch: 32/50, Loss: 0.087, R2 score: 0.9964
Epoch: 33/50, Loss: 0.1179, R2 score: 0.9951
Epoch: 34/50, Loss: 0.0936, R2 score: 0.9961
Epoch: 35/50, Loss: 0.0892, R2 score: 0.9963
Epoch: 36/50, Loss: 0.0852, R2 score: 0.9965
Epoch: 37/50, Loss: 0.0939, R2 score: 0.9961
Epoch: 38/50, Loss: 0.0883, R2 score: 0.9964
Epoch: 39/50, Loss: 0.063, R2 score: 0.9974
Epoch: 40/50, Loss: 0.079, R2 score: 0.9967
Epoch: 41/50, Loss: 0.0675, R2 score: 0.9972
Epoch: 42/50, Loss: 0.0761, R2 score: 0.9969
Epoch: 43/50, Loss: 0.06, R2 score: 0.9975
Epoch: 44/50, Loss: 0.06, R2 score: 0.9975
Epoch: 45/50, Loss: 0.0608, R2 score: 0.9975
Epoch: 46/50, Loss: 0.062, R2 score: 0.9974
Epoch: 47/50, Loss: 0.045, R2 score: 0.9981
Epoch: 48/50, Loss: 0.0477, R2 score: 0.998
Epoch: 49/50, Loss: 0.0453, R2 score: 0.9981
Epoch: 50/50, Loss: 0.0424, R2 score: 0.9982
Test dataset. Loss: 0.0298, R2 score: 0.9988
MSE: 0.0298, r2: 0.9988, Fit time: 1.5387 seconds
.
Regression. Testing func_linear
Epoch: 1/50, Loss: 2.6196, R2 score: 0.3838
Epoch: 2/50, Loss: 0.572, R2 score: 0.8654
Epoch: 3/50, Loss: 0.066, R2 score: 0.9845
Epoch: 4/50, Loss: 0.0232, R2 score: 0.9945
Epoch: 5/50, Loss: 0.0167, R2 score: 0.9961
Epoch: 6/50, Loss: 0.0127, R2 score: 0.997
Epoch: 7/50, Loss: 0.01, R2 score: 0.9976
Epoch: 8/50, Loss: 0.008, R2 score: 0.9981
Epoch: 9/50, Loss: 0.0066, R2 score: 0.9984
Epoch: 10/50, Loss: 0.0056, R2 score: 0.9987
Epoch: 11/50, Loss: 0.0048, R2 score: 0.9989
Epoch: 12/50, Loss: 0.0041, R2 score: 0.999
Epoch: 13/50, Loss: 0.0036, R2 score: 0.9992
Epoch: 14/50, Loss: 0.0032, R2 score: 0.9992
Epoch: 15/50, Loss: 0.0029, R2 score: 0.9993
Epoch: 16/50, Loss: 0.0026, R2 score: 0.9994
Epoch: 17/50, Loss: 0.0023, R2 score: 0.9995
Epoch: 18/50, Loss: 0.0021, R2 score: 0.9995
Epoch: 19/50, Loss: 0.002, R2 score: 0.9995
Epoch: 20/50, Loss: 0.0018, R2 score: 0.9996
Epoch: 21/50, Loss: 0.0017, R2 score: 0.9996
Epoch: 22/50, Loss: 0.0015, R2 score: 0.9996
Epoch: 23/50, Loss: 0.0014, R2 score: 0.9997
Epoch: 24/50, Loss: 0.0013, R2 score: 0.9997
Epoch: 25/50, Loss: 0.0012, R2 score: 0.9997
Epoch: 26/50, Loss: 0.0011, R2 score: 0.9997
Epoch: 27/50, Loss: 0.0011, R2 score: 0.9997
Epoch: 28/50, Loss: 0.001, R2 score: 0.9998
Epoch: 29/50, Loss: 0.0009, R2 score: 0.9998
Epoch: 30/50, Loss: 0.0009, R2 score: 0.9998
Epoch: 31/50, Loss: 0.0008, R2 score: 0.9998
Epoch: 32/50, Loss: 0.0008, R2 score: 0.9998
Epoch: 33/50, Loss: 0.0007, R2 score: 0.9998
Epoch: 34/50, Loss: 0.0007, R2 score: 0.9998
Epoch: 35/50, Loss: 0.0007, R2 score: 0.9998
Epoch: 36/50, Loss: 0.0006, R2 score: 0.9998
Epoch: 37/50, Loss: 0.0006, R2 score: 0.9999
Epoch: 38/50, Loss: 0.0006, R2 score: 0.9999
Epoch: 39/50, Loss: 0.0006, R2 score: 0.9999
Epoch: 40/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 41/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 42/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 43/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 44/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 45/50, Loss: 0.0005, R2 score: 0.9999
Epoch: 46/50, Loss: 0.0004, R2 score: 0.9999
Epoch: 47/50, Loss: 0.0004, R2 score: 0.9999
Epoch: 48/50, Loss: 0.0004, R2 score: 0.9999
Epoch: 49/50, Loss: 0.0004, R2 score: 0.9999
Epoch: 50/50, Loss: 0.0004, R2 score: 0.9999
Test dataset. Loss: 0.0004, R2 score: 0.9999
MSE: 0.0004, r2: 0.9999, Fit time: 1.5058 seconds
.
Regression. Testing func_quadratic_3d
Epoch: 1/20, Loss: 2.1756, R2 score: 0.0952
Epoch: 2/20, Loss: 1.0954, R2 score: 0.5444
Epoch: 3/20, Loss: 0.743, R2 score: 0.691
Epoch: 4/20, Loss: 0.4506, R2 score: 0.8126
Epoch: 5/20, Loss: 0.2413, R2 score: 0.8997
Epoch: 6/20, Loss: 0.1241, R2 score: 0.9484
Epoch: 7/20, Loss: 0.0675, R2 score: 0.9719
Epoch: 8/20, Loss: 0.0431, R2 score: 0.9821
Epoch: 9/20, Loss: 0.0326, R2 score: 0.9865
Epoch: 10/20, Loss: 0.0271, R2 score: 0.9887
Epoch: 11/20, Loss: 0.0238, R2 score: 0.9901
Epoch: 12/20, Loss: 0.0214, R2 score: 0.9911
Epoch: 13/20, Loss: 0.0197, R2 score: 0.9918
Epoch: 14/20, Loss: 0.0181, R2 score: 0.9925
Epoch: 15/20, Loss: 0.0168, R2 score: 0.993
Epoch: 16/20, Loss: 0.0156, R2 score: 0.9935
Epoch: 17/20, Loss: 0.0145, R2 score: 0.994
Epoch: 18/20, Loss: 0.0135, R2 score: 0.9944
Epoch: 19/20, Loss: 0.0128, R2 score: 0.9947
Epoch: 20/20, Loss: 0.0119, R2 score: 0.9951
Test dataset. Loss: 0.0125, R2 score: 0.9951
MSE: 0.0125, r2: 0.9951, Fit time: 26.8006 seconds
.
Regression. Testing func_sin_plus_cos_3d
Epoch: 1/20, Loss: 0.302, R2 score: 0.3754
Epoch: 2/20, Loss: 0.1139, R2 score: 0.7645
Epoch: 3/20, Loss: 0.0604, R2 score: 0.8752
Epoch: 4/20, Loss: 0.0321, R2 score: 0.9337
Epoch: 5/20, Loss: 0.0181, R2 score: 0.9626
Epoch: 6/20, Loss: 0.0158, R2 score: 0.9672
Epoch: 7/20, Loss: 0.0087, R2 score: 0.982
Epoch: 8/20, Loss: 0.0073, R2 score: 0.9848
Epoch: 9/20, Loss: 0.0071, R2 score: 0.9853
Epoch: 10/20, Loss: 0.006, R2 score: 0.9875
Epoch: 11/20, Loss: 0.0047, R2 score: 0.9903
Epoch: 12/20, Loss: 0.005, R2 score: 0.9897
Epoch: 13/20, Loss: 0.0053, R2 score: 0.989
Epoch: 14/20, Loss: 0.0039, R2 score: 0.992
Epoch: 15/20, Loss: 0.0035, R2 score: 0.9928
Epoch: 16/20, Loss: 0.0035, R2 score: 0.9927
Epoch: 17/20, Loss: 0.0031, R2 score: 0.9935
Epoch: 18/20, Loss: 0.0023, R2 score: 0.9952
Epoch: 19/20, Loss: 0.0022, R2 score: 0.9955
Epoch: 20/20, Loss: 0.0022, R2 score: 0.9955
Test dataset. Loss: 0.004, R2 score: 0.9918
MSE: 0.004, r2: 0.9918, Fit time: 27.0536 seconds
.

========================= 9 passed in 87.67s (0:01:27) =========================










Epoch: 1/10, train loss: 2.0412, train Accuracy: 0.565, test loss: 1.8861, test Accuracy: 0.79, epoch time: 94.741 s
Epoch: 2/10, train loss: 1.7296, train Accuracy: 0.91, test loss: 1.7429, test Accuracy: 0.84, epoch time: 95.952 s
Epoch: 3/10, train loss: 1.61, train Accuracy: 0.985, test loss: 1.8214, test Accuracy: 0.79, epoch time: 95.057 s
Epoch: 4/10, train loss: 1.5484, train Accuracy: 0.9925, test loss: 1.8267, test Accuracy: 0.84, epoch time: 95.92 s
Epoch: 5/10, train loss: 1.507, train Accuracy: 0.9975, test loss: 1.7869, test Accuracy: 0.82, epoch time: 94.766 s
Epoch: 6/10, train loss: 1.4937, train Accuracy: 1.0, test loss: 1.7903, test Accuracy: 0.85, epoch time: 94.791 s
Epoch: 7/10, train loss: 1.4918, train Accuracy: 1.0, test loss: 1.7841, test Accuracy: 0.83, epoch time: 94.735 s
Epoch: 8/10, train loss: 1.4882, train Accuracy: 1.0, test loss: 1.7989, test Accuracy: 0.79, epoch time: 94.923 s
Epoch: 9/10, train loss: 1.501, train Accuracy: 1.0, test loss: 1.8038, test Accuracy: 0.83, epoch time: 95.724 s
Epoch: 10/10, train loss: 1.4946, train Accuracy: 1.0, test loss: 1.7927, test Accuracy: 0.81, epoch time: 94.916 s
exec time:  951.5250964164734



platform linux -- Python 3.12.3, pytest-8.3.2, pluggy-1.5.0
rootdir: /home/vlad/Documents/Projects/vladk-neural-network
configfile: pyproject.toml
testpaths: tests
plugins: anyio-4.4.0
collected 9 items

tests/test_binary_classification.py
Binary classification. Testing Iris-setosa - Iris-versicolor combination
BCE: 0.0001, Accuracy: 1.0, Fit time: 2.3385 seconds
.
Binary classification. Testing Iris-versicolor - Iris-virginica combination
BCE: 0.0876, Accuracy: 0.9667, Fit time: 2.4131 seconds
.
Binary classification. Testing Iris-setosa - Iris-virginica combination
BCE: 0.0, Accuracy: 1.0, Fit time: 2.3376 seconds
.
tests/test_multi_classification.py
Multi-class classification. Testing on full Iris dataset (3 species)
CCE: 0.5975, Accuracy: 0.9714, Fit time: 3.4826 seconds
.
Multi-class classification. Testing on Digits dataset
CCE: 1.6147, Accuracy: 0.92, Fit time: 21.3928 seconds
.
tests/test_regression.py
Regression. Testing func_quadratic
MSE: 0.066, R2: 0.9974, Fit time: 2.306 seconds
.
Regression. Testing func_linear
MSE: 0.0, R2: 1.0, Fit time: 2.1879 seconds
.
Regression. Testing func_quadratic_3d
MSE: 0.0015, R2: 0.9994, Fit time: 14.5469 seconds
.
Regression. Testing func_sin_plus_cos_3d
MSE: 0.006, R2: 0.9876, Fit time: 13.7865 seconds
.


return train_dataset[:400], train_dataset[400:500]
layers = [
    Convolutional(LeakyRelu(), filters_num=2, kernel_size=3),
    Convolutional(LeakyRelu(), filters_num=4, kernel_size=3),
    Convolutional(LeakyRelu(), filters_num=8, kernel_size=3),
    Flatten(),
    FullyConnected(128, LeakyRelu()),
    FullyConnected(10, Linear())
]
Epoch: 1/10, train loss: 2.0568, train Accuracy: 0.6025, test loss: 1.7924, test Accuracy: 0.78, epoch time: 162.436s
Epoch: 2/10, train loss: 1.7317, train Accuracy: 0.9375, test loss: 1.8528, test Accuracy: 0.85, epoch time: 160.067s
Epoch: 3/10, train loss: 1.6135, train Accuracy: 0.9975, test loss: 1.8392, test Accuracy: 0.78, epoch time: 159.618s
Epoch: 4/10, train loss: 1.5519, train Accuracy: 0.9975, test loss: 1.8224, test Accuracy: 0.8, epoch time: 161.588s
Epoch: 5/10, train loss: 1.5255, train Accuracy: 1.0, test loss: 1.835, test Accuracy: 0.77, epoch time: 159.78s
Epoch: 6/10, train loss: 1.5098, train Accuracy: 1.0, test loss: 1.7875, test Accuracy: 0.88, epoch time: 158.221s
Epoch: 7/10, train loss: 1.5211, train Accuracy: 1.0, test loss: 1.8637, test Accuracy: 0.8, epoch time: 159.314s
Epoch: 8/10, train loss: 1.5451, train Accuracy: 0.9975, test loss: 1.7577, test Accuracy: 0.81, epoch time: 165.983s
Epoch: 9/10, train loss: 1.5288, train Accuracy: 1.0, test loss: 1.7637, test Accuracy: 0.88, epoch time: 164.638s
Epoch: 10/10, train loss: 1.5167, train Accuracy: 1.0, test loss: 1.8835, test Accuracy: 0.79, epoch time: 164.414s
exec time:  1616.0604257583618



return train_dataset[:800], train_dataset[800:1000]
layers = [
    FullyConnected(256, LeakyRelu()),
    FullyConnected(128, LeakyRelu()),
    FullyConnected(64, LeakyRelu()),
    FullyConnected(10, Linear()),
]
Epoch: 1/30, train loss: 1.9564, train Accuracy: 0.625, test loss: 1.8058, test Accuracy: 0.815, epoch time: 1.105s
Epoch: 2/30, train loss: 1.6986, train Accuracy: 0.8675, test loss: 1.6776, test Accuracy: 0.845, epoch time: 1.162s
Epoch: 3/30, train loss: 1.6143, train Accuracy: 0.9325, test loss: 1.7015, test Accuracy: 0.87, epoch time: 1.103s
Epoch: 4/30, train loss: 1.5668, train Accuracy: 0.9613, test loss: 1.6659, test Accuracy: 0.875, epoch time: 1.128s
Epoch: 5/30, train loss: 1.5308, train Accuracy: 0.9875, test loss: 1.6414, test Accuracy: 0.895, epoch time: 1.051s
Epoch: 6/30, train loss: 1.5088, train Accuracy: 0.99, test loss: 1.6321, test Accuracy: 0.875, epoch time: 1.107s
Epoch: 7/30, train loss: 1.4967, train Accuracy: 0.995, test loss: 1.6244, test Accuracy: 0.87, epoch time: 1.119s
Epoch: 8/30, train loss: 1.4983, train Accuracy: 0.9938, test loss: 1.6564, test Accuracy: 0.895, epoch time: 1.067s
Epoch: 9/30, train loss: 1.4932, train Accuracy: 0.9962, test loss: 1.6491, test Accuracy: 0.89, epoch time: 1.09s
Epoch: 10/30, train loss: 1.4864, train Accuracy: 0.9962, test loss: 1.6088, test Accuracy: 0.88, epoch time: 1.094s
Epoch: 11/30, train loss: 1.4853, train Accuracy: 0.9962, test loss: 1.6272, test Accuracy: 0.87, epoch time: 1.091s
Epoch: 12/30, train loss: 1.4701, train Accuracy: 1.0, test loss: 1.6039, test Accuracy: 0.88, epoch time: 1.064s
Epoch: 13/30, train loss: 1.4733, train Accuracy: 0.9988, test loss: 1.5951, test Accuracy: 0.9, epoch time: 1.087s
Epoch: 14/30, train loss: 1.4917, train Accuracy: 0.995, test loss: 1.6771, test Accuracy: 0.855, epoch time: 1.084s
Epoch: 15/30, train loss: 1.4824, train Accuracy: 0.9975, test loss: 1.5827, test Accuracy: 0.9, epoch time: 1.04s
Epoch: 16/30, train loss: 1.4716, train Accuracy: 1.0, test loss: 1.5812, test Accuracy: 0.895, epoch time: 1.082s
Epoch: 17/30, train loss: 1.469, train Accuracy: 0.9988, test loss: 1.5949, test Accuracy: 0.89, epoch time: 1.083s
Epoch: 18/30, train loss: 1.4681, train Accuracy: 1.0, test loss: 1.5832, test Accuracy: 0.875, epoch time: 1.075s
Epoch: 19/30, train loss: 1.4858, train Accuracy: 0.99, test loss: 1.6011, test Accuracy: 0.895, epoch time: 1.093s
Epoch: 20/30, train loss: 1.4691, train Accuracy: 1.0, test loss: 1.6159, test Accuracy: 0.88, epoch time: 1.15s
Epoch: 21/30, train loss: 1.4701, train Accuracy: 0.9988, test loss: 1.5892, test Accuracy: 0.88, epoch time: 1.092s
Epoch: 22/30, train loss: 1.4775, train Accuracy: 0.995, test loss: 1.6202, test Accuracy: 0.875, epoch time: 1.052s
Epoch: 23/30, train loss: 1.4685, train Accuracy: 1.0, test loss: 1.5899, test Accuracy: 0.89, epoch time: 1.059s
Epoch: 24/30, train loss: 1.4644, train Accuracy: 1.0, test loss: 1.5997, test Accuracy: 0.875, epoch time: 1.074s
Epoch: 25/30, train loss: 1.4809, train Accuracy: 0.995, test loss: 1.6171, test Accuracy: 0.88, epoch time: 1.053s
Epoch: 26/30, train loss: 1.4761, train Accuracy: 0.9962, test loss: 1.6047, test Accuracy: 0.87, epoch time: 1.063s
Epoch: 27/30, train loss: 1.4664, train Accuracy: 1.0, test loss: 1.6139, test Accuracy: 0.865, epoch time: 1.071s
Epoch: 28/30, train loss: 1.4642, train Accuracy: 1.0, test loss: 1.6099, test Accuracy: 0.88, epoch time: 1.11s
Epoch: 29/30, train loss: 1.4642, train Accuracy: 1.0, test loss: 1.6005, test Accuracy: 0.885, epoch time: 1.061s
Epoch: 30/30, train loss: 1.4633, train Accuracy: 1.0, test loss: 1.5951, test Accuracy: 0.885, epoch time: 1.057s
--- 32.57006621360779 seconds ---


layers = [
    Convolutional(LeakyRelu(), filters_num=4, kernel_size=3),
    Convolutional(LeakyRelu(), filters_num=4, kernel_size=3),
    Convolutional(LeakyRelu(), filters_num=4, kernel_size=3),
    Flatten(),
    FullyConnected(128, LeakyRelu()),
    FullyConnected(10, Linear())
]
Epoch: 1/15, train loss: 1.939, train Accuracy: 0.7037, test loss: 1.7799, test Accuracy: 0.875, epoch time: 363.048s
Epoch: 2/15, train loss: 1.6976, train Accuracy: 0.9175, test loss: 1.7182, test Accuracy: 0.87, epoch time: 365.357s
Epoch: 3/15, train loss: 1.6057, train Accuracy: 0.9788, test loss: 1.6302, test Accuracy: 0.925, epoch time: 360.527s
Epoch: 4/15, train loss: 1.5695, train Accuracy: 0.9838, test loss: 1.7497, test Accuracy: 0.88, epoch time: 358.178s
Epoch: 5/15, train loss: 1.5402, train Accuracy: 0.9975, test loss: 1.6659, test Accuracy: 0.915, epoch time: 359.292s
Epoch: 6/15, train loss: 1.5138, train Accuracy: 1.0, test loss: 1.6235, test Accuracy: 0.925, epoch time: 357.846s
Epoch: 7/15, train loss: 1.5101, train Accuracy: 1.0, test loss: 1.6034, test Accuracy: 0.93, epoch time: 358.258s
Epoch: 8/15, train loss: 1.4963, train Accuracy: 1.0, test loss: 1.5893, test Accuracy: 0.92, epoch time: 359.548s
Epoch: 9/15, train loss: 1.4891, train Accuracy: 1.0, test loss: 1.7042, test Accuracy: 0.905, epoch time: 362.712s
Epoch: 10/15, train loss: 1.4958, train Accuracy: 1.0, test loss: 1.6438, test Accuracy: 0.92, epoch time: 361.976s
Epoch: 11/15, train loss: 1.4908, train Accuracy: 1.0, test loss: 1.6318, test Accuracy: 0.895, epoch time: 361.59s
Epoch: 12/15, train loss: 1.4874, train Accuracy: 1.0, test loss: 1.6377, test Accuracy: 0.915, epoch time: 360.399s
Epoch: 13/15, train loss: 1.4879, train Accuracy: 1.0, test loss: 1.6226, test Accuracy: 0.94, epoch time: 359.11s
Epoch: 14/15, train loss: 1.485, train Accuracy: 1.0, test loss: 1.6146, test Accuracy: 0.915, epoch time: 364.369s
Epoch: 15/15, train loss: 1.4799, train Accuracy: 1.0, test loss: 1.6611, test Accuracy: 0.93, epoch time: 362.149s
exec time:  5414.361704349518


layer_error
tensor([[[ 7.5428e-04, -1.9525e-04, -1.3240e-03,  2.2925e-02],
         [ 2.1448e-03, -2.1429e-03,  8.1483e-04,  8.4673e-03],
         [ 7.9308e-05, -3.0675e-03,  3.5140e-03, -1.6897e-02],
         [-2.2638e-01,  1.6438e-01, -1.8934e-01, -1.8707e-03]],

        [[ 6.8957e-02, -8.7830e-02, -1.5290e-02, -1.4721e-04],
         [ 1.3041e-02, -4.0039e-04,  2.9343e-03,  1.7664e-02],
         [-2.0738e-01, -1.7901e-04, -3.6541e-03, -1.2346e-01],
         [ 1.3839e-03,  1.1451e-03,  2.3403e-03,  1.8894e-01]]])


forward single core
Forward time:  0.06352400779724121
Forward time:  0.1104423999786377
Forward time:  0.18530988693237305

Forward time:  0.06598258018493652
Forward time:  0.11107468605041504
Forward time:  0.18769335746765137

Forward time:  0.06174159049987793
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2717e-01,
          4.0219e-02, -2.3236e-04,  2.3859e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.3600e-02,  4.1662e-02, -2.1981e-04,  1.4565e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0900e-02,  2.5272e-01,
          1.7032e-01,  2.3872e-01,  2.1286e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7855e-02,
          1.6288e-01,  1.2766e-01,  6.8591e-02,  1.4232e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.8167e-03,  1.1279e-01,  4.8129e-02,
         -1.2544e-03,  1.3342e-01,  1.6876e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.4321e-02,
          1.7961e-01,  5.1010e-02,  2.0595e-01,  2.0364e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.3863e-02,  1.9274e-01,  1.2906e-02,
         -8.9223e-04,  1.0568e-01,  4.8241e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7250e-02,  1.5315e-01,
         -1.1584e-05, -1.3809e-03,  8.8352e-02,  4.1196e-02,  0.0000e+00,
          0.0000e+00,  1.8772e-02,  1.7236e-01,  8.4113e-02, -3.9078e-04,
          1.7320e-02,  1.3321e-01, -4.2065e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9378e-02,  1.6099e-01,  1.1219e-01,
         -3.7868e-04,  4.9846e-02,  1.6558e-01,  4.4804e-02,  0.0000e+00,
          4.8444e-03,  1.1895e-01,  1.2738e-01, -1.2749e-04, -8.8952e-04,
          5.1228e-02,  3.6061e-02, -7.4654e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  9.1601e-02,  2.0416e-01,  3.9240e-02,
         -3.1554e-04,  1.1966e-02,  3.1401e-02, -2.0841e-04,  0.0000e+00,
          5.1210e-02,  1.9101e-01,  3.7000e-02, -4.1415e-04, -1.1964e-05,
          8.4605e-02, -1.0887e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.5167e-01,  8.9318e-03, -3.3090e-04,
         -1.7116e-04,  7.9929e-02,  5.9826e-03,  8.5086e-03,  1.9970e-02,
          1.7126e-01,  6.6202e-02, -6.7818e-04, -6.6460e-04,  3.9016e-02,
         -2.0007e-04, -7.1543e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.4217e-02, -2.9920e-04,  5.1060e-02,
          2.0605e-01,  2.7236e-01,  1.9732e-01,  1.4778e-01,  1.3247e-01,
          1.9460e-01, -2.4695e-05, -5.7735e-04,  1.8313e-02,  1.8211e-03,
         -1.8041e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -1.2266e-03, -2.1061e-03, -8.6119e-04,
          1.9850e-01,  3.7629e-01,  4.2380e-01,  5.4257e-01,  4.8012e-01,
          2.9603e-01, -3.9939e-04, -1.4530e-04,  2.8193e-02, -3.3905e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -8.2072e-04, -2.6241e-03, -3.6059e-03,
         -3.4992e-03, -2.4430e-03, -1.5360e-03, -2.3479e-04, -8.7804e-04,
         -4.3883e-04, -6.2650e-04,  7.6560e-02, -3.1390e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5716e-04, -1.0435e-03,
         -2.2358e-03, -2.9590e-03, -9.5020e-04, -9.1918e-04, -9.7484e-04,
         -9.7103e-04,  5.5149e-02,  2.8209e-02, -5.9101e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.4222e-03,  1.1358e-01,  1.4865e-01, -1.5467e-05, -6.5995e-04,
         -8.6402e-05,  2.7592e-02, -3.2972e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6333e-03,
          9.7050e-02,  1.9012e-01,  5.8823e-02, -3.5955e-04, -5.0392e-04,
          5.1469e-02, -4.6226e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1721e-02,
          2.0094e-01,  9.1892e-02,  1.3487e-02, -7.9387e-04,  4.8009e-02,
         -2.7134e-04, -1.5553e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2094e-02,  1.6733e-01,
          9.2133e-02, -2.2600e-04, -7.0128e-04,  2.3389e-02,  1.3328e-03,
         -1.3064e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.6611e-03,  1.3381e-01,  1.4105e-01,
         -1.0948e-04, -7.7166e-04, -2.1134e-04, -1.2738e-04, -3.0795e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  5.1490e-02,  1.7700e-01,  8.3662e-03,
         -9.3135e-04, -2.4589e-04,  1.3811e-02, -3.5636e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.8444e-03,  1.6017e-01,  6.0449e-02, -6.1923e-04,
         -5.8666e-04,  7.6501e-02, -3.1487e-04, -9.3317e-06,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0638e-02,  1.7186e-01, -1.8494e-04, -5.3188e-04,
          6.5871e-02,  8.1131e-02, -6.2211e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.5170e-05, -9.0845e-04, -2.0934e-03, -7.8778e-04,
          7.4480e-02, -3.0708e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -9.6042e-05, -1.9459e-03, -3.5577e-03, -2.6411e-03,
         -1.0001e-03, -1.2442e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]])
Forward time:  0.11795353889465332
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9448e-02, -1.3394e-04,  1.6136e-02,
         -1.4403e-04, -3.0783e-04,  5.2576e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6680e-03, -1.7184e-05,
          3.3569e-03,  1.9148e-03, -2.9179e-04,  3.2096e-02,  0.0000e+00,
          0.0000e+00,  1.6670e-03,  6.7456e-02, -4.1188e-04,  8.9892e-02,
          5.7028e-02, -2.8801e-04,  4.0151e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.2601e-03,  3.0311e-02, -1.0512e-04,
          2.6662e-02,  3.4798e-02, -3.3606e-04,  5.1770e-02,  0.0000e+00,
          2.7783e-04,  1.9556e-02,  1.3003e-02, -3.6800e-04,  7.0696e-02,
          7.1244e-02, -1.8654e-04,  1.0146e-01,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1178e-02,  2.7758e-02, -2.4116e-04,
          6.0900e-02,  7.6189e-02, -2.3254e-04,  5.9739e-02,  0.0000e+00,
          1.0207e-02,  4.1603e-02, -1.1557e-03, -8.5520e-05,  5.5991e-02,
         -1.5406e-03,  1.4917e-02,  8.9662e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.1675e-03,  3.4479e-02, -4.9356e-04, -2.9308e-05,
          8.2434e-02, -6.6954e-04, -3.2382e-04,  1.2540e-01,  2.8709e-03,
          3.7919e-02, -1.6322e-04, -3.6447e-05, -1.3064e-05,  1.4402e-02,
         -9.9048e-04,  8.2713e-02,  4.9932e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.9635e-03,  2.7631e-02, -6.9050e-05, -6.6057e-04, -3.4294e-04,
          4.6258e-02, -1.4014e-03,  1.0149e-01,  2.8385e-02,  2.1843e-02,
          1.7339e-02, -7.9575e-04,  8.4963e-03,  5.1337e-02, -6.9329e-04,
         -2.5871e-04,  1.2232e-01,  2.2015e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.8707e-02,  3.8910e-02, -6.9797e-04,  1.7026e-02,  9.1902e-02,
         -9.4522e-04, -7.1750e-05,  7.7760e-02,  6.0233e-02,  4.2060e-02,
         -6.8824e-04,  1.5627e-02,  5.2962e-04, -1.5874e-04, -6.3030e-04,
          7.4411e-02,  6.8874e-02,  6.3377e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.0705e-02, -4.3294e-04,  8.7893e-03,  3.9081e-02, -2.1345e-04,
         -8.2222e-04,  1.6302e-02,  1.2080e-01,  4.0924e-02, -1.7906e-04,
         -3.2841e-04, -1.3381e-04,  3.2995e-02, -4.3431e-04, -1.6736e-04,
          1.1756e-01,  2.2878e-02,  1.7544e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.2980e-02, -1.1591e-03,  4.6414e-02,  2.7363e-02,  1.7961e-02,
          3.4168e-02,  1.6246e-01,  4.4308e-02,  6.2808e-02, -1.1994e-03,
          2.4454e-02,  6.3542e-02, -3.6735e-04, -6.7487e-04,  1.0794e-01,
          4.7241e-02,  7.6849e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -3.2631e-04, -2.8178e-04, -5.7776e-06,  5.1969e-02,  5.0680e-02,
          9.1135e-02,  1.3176e-01,  9.2688e-02,  8.2152e-02, -1.3204e-04,
          7.8151e-02, -7.4141e-04, -4.4613e-04,  7.3638e-02,  8.8207e-02,
          1.1954e-02,  1.6813e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.2318e-04, -3.5642e-05, -9.3920e-05, -5.4906e-04, -1.4043e-03,
         -5.2258e-05,  1.2030e-01,  8.1644e-03,  3.7544e-02,  9.9969e-03,
          6.1229e-02, -2.3127e-04,  2.3573e-02,  1.2789e-01,  1.0794e-02,
          4.2398e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          5.7220e-03, -2.1177e-04, -2.5094e-04, -7.1029e-04, -5.7710e-04,
         -9.5490e-04, -1.7128e-03, -1.1766e-03, -9.8117e-04, -1.2676e-04,
          1.4999e-03, -4.4621e-04,  1.4483e-01,  2.0606e-02,  7.9680e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.7551e-03,  8.1386e-03,  2.3968e-02,  3.0003e-02,  1.8140e-02,
          8.4319e-02, -5.1004e-05,  1.6792e-02,  4.2339e-02, -1.8983e-04,
         -5.8791e-04,  8.8136e-02,  7.1404e-02,  1.1612e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  9.1056e-04,  5.3049e-03,  2.5947e-02,  6.8357e-02,
         -1.3603e-04,  1.5070e-02,  5.3581e-02, -2.5676e-04, -3.9307e-04,
          1.6322e-02,  1.2101e-01,  1.1201e-02,  1.3889e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0320e-02,  4.0767e-02, -2.1873e-04,
         -2.4565e-04,  2.6398e-02, -1.1196e-04,  3.5696e-03, -4.6947e-04,
          1.6014e-01,  1.4432e-02,  7.7487e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.9084e-03,  3.3718e-02, -5.7235e-05, -5.0851e-04,
         -4.5148e-06, -7.6340e-05,  2.9610e-02, -8.5378e-04,  1.3779e-01,
          3.3990e-02,  1.1978e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.0187e-03,  2.7009e-02,  1.0957e-02, -7.3123e-04, -1.2527e-04,
          1.9300e-02, -6.4409e-05, -9.0252e-04,  8.8378e-02,  7.6273e-02,
          1.4504e-02,  3.6550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          9.4895e-03,  3.9514e-02, -6.8865e-04,  1.2360e-02,  1.8741e-02,
         -4.0763e-04, -4.5876e-04,  5.6339e-02,  1.0900e-01,  1.1337e-02,
          3.0702e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4089e-04,
          3.4465e-02, -2.7877e-04, -2.9894e-04, -1.8016e-04,  5.4224e-02,
         -6.7833e-04,  3.4387e-02,  1.2917e-01,  1.2928e-02,  7.2370e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8013e-03,
          4.5817e-02, -1.0638e-03,  4.9493e-02,  3.2880e-02, -4.1912e-04,
         -2.5154e-04,  1.5015e-01,  2.2694e-02,  9.0434e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4810e-04,
         -1.9305e-04, -8.3201e-04, -1.4927e-04,  5.9382e-02, -7.8189e-04,
          4.3681e-02,  8.4085e-02,  1.1117e-02,  2.1930e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3690e-05,
         -5.4588e-04, -3.5337e-05, -2.2497e-04, -8.0468e-04, -4.1526e-04,
          1.2534e-01,  2.8733e-02,  1.4620e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2526e-05,
          5.0267e-03, -2.9592e-04, -4.1757e-05,  4.3714e-02,  7.7562e-02,
          2.9869e-02,  9.6368e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])
Forward time:  0.18132495880126953
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  3.2476e-04, -2.3155e-05, -1.4006e-07,  6.8807e-04,
         -9.8982e-06,  4.7922e-03, -2.4401e-05,  5.4522e-03,  8.1189e-05,
          3.2475e-03, -1.7453e-04,  1.9871e-02, -5.7595e-05, -1.1498e-04,
          2.3314e-02,  1.0409e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0748e-04, -1.0243e-07, -8.3480e-05,  6.9420e-03,  1.6393e-03,
         -1.2292e-04,  1.8503e-02,  2.4335e-03,  8.0998e-03,  9.0325e-04,
         -2.4224e-05,  2.9262e-03,  4.5757e-02,  5.2620e-04, -1.1443e-04,
          9.7278e-03,  1.8014e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.1732e-03, -2.9636e-05, -1.4187e-05,  2.9315e-02, -6.2409e-05,
         -1.2827e-04,  1.4772e-02,  2.3541e-02, -1.4804e-06, -6.5311e-06,
         -8.6740e-05, -4.9213e-05,  1.8462e-04, -5.7966e-05,  4.4138e-02,
          5.2304e-02, -1.4194e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0297e-04,
          1.0469e-03, -7.0873e-05,  1.0431e-02,  1.9926e-02, -1.8480e-04,
          1.8135e-02,  4.0279e-02,  3.8567e-03,  1.7945e-03, -7.0380e-05,
          6.1347e-03,  2.2408e-02,  1.4110e-03, -4.5747e-04,  2.8645e-02,
          1.2694e-02, -7.8638e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4434e-04,  3.0121e-04,
         -6.3378e-05,  4.2903e-04,  1.6163e-02, -6.5335e-05, -1.9629e-04,
          4.8786e-02,  3.2624e-02, -9.6150e-05,  1.2904e-03, -2.7756e-06,
          1.7189e-02, -3.4389e-06, -1.2159e-04,  3.0720e-02,  3.1958e-02,
          8.3533e-03, -2.3551e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0121e-03, -2.1227e-05,
         -3.9182e-05,  1.2142e-02,  5.9476e-03,  2.5031e-03, -1.8827e-05,
          2.3074e-02, -7.0820e-05,  2.9900e-03, -1.2280e-04,  7.2066e-03,
          1.2441e-02,  7.8226e-03, -1.0195e-04,  3.2992e-02,  2.0228e-02,
         -1.0036e-04,  5.6124e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7036e-03, -6.8323e-05,
          1.0087e-02,  2.0036e-02,  5.7010e-03, -2.2798e-04,  4.4863e-02,
          2.0461e-02,  1.5747e-03, -9.0912e-05,  1.2240e-02,  2.8874e-02,
          3.8654e-05, -2.3393e-04,  3.5331e-02,  2.3113e-02, -4.0731e-05,
         -5.4627e-05,  2.2885e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7552e-03, -3.7683e-05,
          1.3379e-02, -2.9921e-05, -2.9662e-05,  1.0477e-02, -6.8524e-05,
          9.9989e-04, -8.0011e-05,  1.5604e-02,  2.2920e-02, -6.1054e-06,
         -2.7963e-05,  8.2808e-03,  3.2144e-02,  1.3438e-02, -1.5135e-04,
          2.8504e-03, -2.7784e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3610e-06, -7.9035e-05,
          2.7534e-02,  1.4674e-02, -8.0931e-05, -1.2768e-06,  3.8858e-02,
          5.0574e-03,  3.0624e-02,  7.1653e-03,  4.1746e-02,  1.1029e-02,
         -1.2624e-04,  4.4658e-02,  1.0709e-02, -9.9199e-05, -3.6969e-05,
         -2.0027e-05,  1.0195e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8681e-05, -4.5494e-05,
         -3.8812e-05, -1.1878e-04,  1.9076e-02,  4.5562e-02,  5.3924e-02,
          1.4856e-02,  3.0483e-02, -1.0647e-04, -1.0567e-04, -3.0335e-04,
          4.4510e-02,  9.1779e-03,  2.9138e-03, -2.4744e-05,  4.3852e-03,
         -8.4009e-06,  6.8268e-04],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0484e-04, -3.7474e-06,
          6.4221e-03, -3.8630e-05, -1.8713e-05, -9.6831e-05, -4.5777e-04,
         -2.0662e-04,  1.3703e-02,  1.3737e-02, -6.5408e-05,  2.5846e-03,
          7.5661e-03,  2.2836e-02, -9.7554e-05,  1.9443e-03, -7.0373e-05,
          2.0584e-03,  9.6107e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8265e-06,  3.5122e-03,
          7.0656e-03,  1.1214e-02, -8.4223e-05, -6.3677e-05,  1.7045e-03,
         -2.5443e-05, -1.6356e-04, -4.8375e-04, -3.1473e-04,  3.3630e-02,
          2.9652e-02, -6.5960e-05, -2.4554e-05, -1.0776e-04,  3.9022e-03,
          2.4236e-04,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.9429e-06, -2.3409e-05,
         -1.6916e-05,  5.7723e-03,  1.8342e-02,  1.8448e-02,  1.9315e-02,
          2.7612e-02,  2.6347e-02,  2.5435e-02,  6.1825e-02,  2.8886e-02,
         -7.4405e-05, -1.0072e-04, -3.5484e-05,  4.3999e-03,  4.5546e-04,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.9734e-06, -1.5541e-05,
          1.0140e-03, -2.1582e-05, -1.2997e-04,  6.5551e-03,  1.4791e-02,
          1.7632e-02, -1.3304e-04,  1.8620e-02,  1.4707e-02,  7.3450e-03,
         -1.4581e-04,  3.6605e-03, -2.6629e-05,  7.8925e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0552e-04,
         -8.3325e-06, -7.8394e-05,  7.3471e-03,  1.2735e-02, -1.2822e-05,
         -2.3025e-04,  7.2471e-03,  1.4615e-02,  1.9767e-02, -6.8949e-05,
          3.2320e-03, -9.8082e-05,  2.8073e-03,  7.9393e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9615e-05,  1.0722e-03,
         -5.1876e-05,  1.8707e-03,  7.7341e-03,  5.1293e-03, -8.8484e-05,
          8.8636e-03,  2.0506e-02,  1.6639e-02, -3.7179e-05, -4.9405e-05,
         -1.1576e-04,  5.4232e-03,  4.4293e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9869e-04,  1.2188e-04,
         -6.9384e-05,  1.0481e-02,  1.3217e-02, -3.6304e-05, -7.9006e-05,
          3.1144e-02,  1.4128e-02, -2.7015e-05, -8.4053e-05, -1.5721e-05,
          3.8132e-03,  7.1762e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  3.6084e-05,  1.7500e-03, -6.6773e-05,
          3.7587e-03,  2.5550e-02,  1.3651e-03, -1.7565e-04,  3.6599e-02,
          1.3933e-02, -4.3959e-06, -4.6934e-05,  3.1448e-03, -3.8718e-05,
          1.3797e-03,  2.0893e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  1.6057e-04,  3.0006e-03, -1.1184e-04,
          1.4239e-02, -3.4517e-05,  1.2879e-03, -5.9317e-05,  1.8612e-02,
          2.0364e-02, -1.8018e-05,  2.2800e-04, -9.9028e-05,  3.3642e-03,
          1.7550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.3128e-04,  3.6436e-03,  5.2701e-03,
          3.3342e-02,  6.6454e-03, -6.5492e-05,  3.0015e-02,  2.0732e-02,
          2.9801e-03, -4.4991e-05, -1.1458e-04,  4.8447e-03,  4.1368e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -1.2069e-06, -4.8512e-05, -1.3367e-04,
          2.0196e-03,  2.3727e-03, -5.0267e-05,  1.2572e-02,  1.4152e-02,
         -1.3111e-04, -4.7359e-05,  4.3129e-03,  5.3671e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -2.5901e-06, -2.0900e-05, -5.3669e-05,
          1.4086e-03, -6.4758e-05, -1.1111e-05,  1.9125e-03, -1.0002e-04,
          3.7343e-04, -1.0918e-05,  8.5120e-04,  1.2536e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00]])
















Forward time:  0.00933837890625
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2717e-01,
          4.0219e-02, -2.3236e-04,  2.3859e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.3600e-02,  4.1662e-02, -2.1981e-04,  1.4565e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0900e-02,  2.5272e-01,
          1.7032e-01,  2.3872e-01,  2.1286e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7855e-02,
          1.6288e-01,  1.2766e-01,  6.8591e-02,  1.4232e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.8167e-03,  1.1279e-01,  4.8129e-02,
         -1.2544e-03,  1.3342e-01,  1.6876e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.4321e-02,
          1.7961e-01,  5.1010e-02,  2.0595e-01,  2.0364e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.3863e-02,  1.9274e-01,  1.2906e-02,
         -8.9223e-04,  1.0568e-01,  4.8241e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7250e-02,  1.5315e-01,
         -1.1584e-05, -1.3809e-03,  8.8352e-02,  4.1196e-02,  0.0000e+00,
          0.0000e+00,  1.8772e-02,  1.7236e-01,  8.4113e-02, -3.9078e-04,
          1.7320e-02,  1.3321e-01, -4.2065e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9378e-02,  1.6099e-01,  1.1219e-01,
         -3.7868e-04,  4.9846e-02,  1.6558e-01,  4.4804e-02,  0.0000e+00,
          4.8444e-03,  1.1895e-01,  1.2738e-01, -1.2749e-04, -8.8952e-04,
          5.1228e-02,  3.6061e-02, -7.4654e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  9.1601e-02,  2.0416e-01,  3.9240e-02,
         -3.1554e-04,  1.1966e-02,  3.1401e-02, -2.0841e-04,  0.0000e+00,
          5.1210e-02,  1.9101e-01,  3.7000e-02, -4.1415e-04, -1.1964e-05,
          8.4605e-02, -1.0887e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.5167e-01,  8.9318e-03, -3.3090e-04,
         -1.7116e-04,  7.9929e-02,  5.9826e-03,  8.5086e-03,  1.9970e-02,
          1.7126e-01,  6.6202e-02, -6.7818e-04, -6.6460e-04,  3.9016e-02,
         -2.0007e-04, -7.1543e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.4217e-02, -2.9920e-04,  5.1060e-02,
          2.0605e-01,  2.7236e-01,  1.9732e-01,  1.4778e-01,  1.3247e-01,
          1.9460e-01, -2.4695e-05, -5.7735e-04,  1.8313e-02,  1.8211e-03,
         -1.8041e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -1.2266e-03, -2.1061e-03, -8.6119e-04,
          1.9850e-01,  3.7629e-01,  4.2380e-01,  5.4257e-01,  4.8012e-01,
          2.9603e-01, -3.9939e-04, -1.4530e-04,  2.8193e-02, -3.3905e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -8.2072e-04, -2.6241e-03, -3.6059e-03,
         -3.4992e-03, -2.4430e-03, -1.5360e-03, -2.3479e-04, -8.7804e-04,
         -4.3883e-04, -6.2650e-04,  7.6560e-02, -3.1390e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5716e-04, -1.0435e-03,
         -2.2358e-03, -2.9590e-03, -9.5020e-04, -9.1918e-04, -9.7484e-04,
         -9.7103e-04,  5.5149e-02,  2.8209e-02, -5.9101e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.4222e-03,  1.1358e-01,  1.4865e-01, -1.5467e-05, -6.5995e-04,
         -8.6402e-05,  2.7592e-02, -3.2972e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6333e-03,
          9.7050e-02,  1.9012e-01,  5.8823e-02, -3.5955e-04, -5.0392e-04,
          5.1469e-02, -4.6226e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1721e-02,
          2.0094e-01,  9.1892e-02,  1.3487e-02, -7.9387e-04,  4.8009e-02,
         -2.7134e-04, -1.5553e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2094e-02,  1.6733e-01,
          9.2133e-02, -2.2600e-04, -7.0128e-04,  2.3389e-02,  1.3328e-03,
         -1.3064e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.6611e-03,  1.3381e-01,  1.4105e-01,
         -1.0948e-04, -7.7166e-04, -2.1134e-04, -1.2738e-04, -3.0795e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  5.1490e-02,  1.7700e-01,  8.3662e-03,
         -9.3135e-04, -2.4589e-04,  1.3811e-02, -3.5636e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.8444e-03,  1.6017e-01,  6.0449e-02, -6.1923e-04,
         -5.8666e-04,  7.6501e-02, -3.1487e-04, -9.3317e-06,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0638e-02,  1.7186e-01, -1.8494e-04, -5.3188e-04,
          6.5871e-02,  8.1131e-02, -6.2211e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.5170e-05, -9.0845e-04, -2.0934e-03, -7.8778e-04,
          7.4480e-02, -3.0708e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -9.6042e-05, -1.9459e-03, -3.5577e-03, -2.6411e-03,
         -1.0001e-03, -1.2442e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]])



Forward time:  0.012391090393066406
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9448e-02, -1.3394e-04,  1.6136e-02,
         -1.4403e-04, -3.0783e-04,  5.2576e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6680e-03, -1.7184e-05,
          3.3569e-03,  1.9148e-03, -2.9179e-04,  3.2096e-02,  0.0000e+00,
          0.0000e+00,  1.6670e-03,  6.7456e-02, -4.1188e-04,  8.9892e-02,
          5.7028e-02, -2.8801e-04,  4.0151e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.2601e-03,  3.0311e-02, -1.0512e-04,
          2.6662e-02,  3.4798e-02, -3.3606e-04,  5.1770e-02,  0.0000e+00,
          2.7783e-04,  1.9556e-02,  1.3003e-02, -3.6800e-04,  7.0696e-02,
          7.1244e-02, -1.8654e-04,  1.0146e-01,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1178e-02,  2.7758e-02, -2.4116e-04,
          6.0900e-02,  7.6189e-02, -2.3254e-04,  5.9739e-02,  0.0000e+00,
          1.0207e-02,  4.1603e-02, -1.1557e-03, -8.5520e-05,  5.5991e-02,
         -1.5406e-03,  1.4917e-02,  8.9662e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.1675e-03,  3.4479e-02, -4.9356e-04, -2.9308e-05,
          8.2434e-02, -6.6954e-04, -3.2382e-04,  1.2540e-01,  2.8709e-03,
          3.7919e-02, -1.6322e-04, -3.6447e-05, -1.3064e-05,  1.4402e-02,
         -9.9048e-04,  8.2713e-02,  4.9932e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.9635e-03,  2.7631e-02, -6.9050e-05, -6.6057e-04, -3.4294e-04,
          4.6258e-02, -1.4014e-03,  1.0149e-01,  2.8385e-02,  2.1843e-02,
          1.7339e-02, -7.9575e-04,  8.4963e-03,  5.1337e-02, -6.9329e-04,
         -2.5871e-04,  1.2232e-01,  2.2015e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.8707e-02,  3.8910e-02, -6.9797e-04,  1.7026e-02,  9.1902e-02,
         -9.4522e-04, -7.1750e-05,  7.7760e-02,  6.0233e-02,  4.2060e-02,
         -6.8824e-04,  1.5627e-02,  5.2962e-04, -1.5874e-04, -6.3030e-04,
          7.4411e-02,  6.8874e-02,  6.3377e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.0705e-02, -4.3294e-04,  8.7893e-03,  3.9081e-02, -2.1345e-04,
         -8.2222e-04,  1.6302e-02,  1.2080e-01,  4.0924e-02, -1.7906e-04,
         -3.2841e-04, -1.3381e-04,  3.2995e-02, -4.3431e-04, -1.6736e-04,
          1.1756e-01,  2.2878e-02,  1.7544e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.2980e-02, -1.1591e-03,  4.6414e-02,  2.7363e-02,  1.7961e-02,
          3.4168e-02,  1.6246e-01,  4.4308e-02,  6.2808e-02, -1.1994e-03,
          2.4454e-02,  6.3542e-02, -3.6735e-04, -6.7487e-04,  1.0794e-01,
          4.7241e-02,  7.6849e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -3.2631e-04, -2.8178e-04, -5.7776e-06,  5.1969e-02,  5.0680e-02,
          9.1135e-02,  1.3176e-01,  9.2688e-02,  8.2152e-02, -1.3204e-04,
          7.8151e-02, -7.4141e-04, -4.4613e-04,  7.3638e-02,  8.8207e-02,
          1.1954e-02,  1.6813e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.2318e-04, -3.5642e-05, -9.3920e-05, -5.4906e-04, -1.4043e-03,
         -5.2258e-05,  1.2030e-01,  8.1644e-03,  3.7544e-02,  9.9969e-03,
          6.1229e-02, -2.3127e-04,  2.3573e-02,  1.2789e-01,  1.0794e-02,
          4.2398e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          5.7220e-03, -2.1177e-04, -2.5094e-04, -7.1029e-04, -5.7710e-04,
         -9.5490e-04, -1.7128e-03, -1.1766e-03, -9.8117e-04, -1.2676e-04,
          1.4999e-03, -4.4621e-04,  1.4483e-01,  2.0606e-02,  7.9680e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.7551e-03,  8.1386e-03,  2.3968e-02,  3.0003e-02,  1.8140e-02,
          8.4319e-02, -5.1004e-05,  1.6792e-02,  4.2339e-02, -1.8983e-04,
         -5.8791e-04,  8.8136e-02,  7.1404e-02,  1.1612e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  9.1056e-04,  5.3049e-03,  2.5947e-02,  6.8357e-02,
         -1.3603e-04,  1.5070e-02,  5.3581e-02, -2.5676e-04, -3.9307e-04,
          1.6322e-02,  1.2101e-01,  1.1201e-02,  1.3889e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0320e-02,  4.0767e-02, -2.1873e-04,
         -2.4565e-04,  2.6398e-02, -1.1196e-04,  3.5696e-03, -4.6947e-04,
          1.6014e-01,  1.4432e-02,  7.7487e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.9084e-03,  3.3718e-02, -5.7235e-05, -5.0851e-04,
         -4.5148e-06, -7.6340e-05,  2.9610e-02, -8.5378e-04,  1.3779e-01,
          3.3990e-02,  1.1978e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.0187e-03,  2.7009e-02,  1.0957e-02, -7.3123e-04, -1.2527e-04,
          1.9300e-02, -6.4409e-05, -9.0252e-04,  8.8378e-02,  7.6273e-02,
          1.4504e-02,  3.6550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          9.4895e-03,  3.9514e-02, -6.8865e-04,  1.2360e-02,  1.8741e-02,
         -4.0763e-04, -4.5876e-04,  5.6339e-02,  1.0900e-01,  1.1337e-02,
          3.0702e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4089e-04,
          3.4465e-02, -2.7877e-04, -2.9894e-04, -1.8016e-04,  5.4224e-02,
         -6.7833e-04,  3.4387e-02,  1.2917e-01,  1.2928e-02,  7.2370e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8013e-03,
          4.5817e-02, -1.0638e-03,  4.9493e-02,  3.2880e-02, -4.1912e-04,
         -2.5154e-04,  1.5015e-01,  2.2694e-02,  9.0434e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4810e-04,
         -1.9305e-04, -8.3201e-04, -1.4927e-04,  5.9382e-02, -7.8189e-04,
          4.3681e-02,  8.4085e-02,  1.1117e-02,  2.1930e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3690e-05,
         -5.4588e-04, -3.5337e-05, -2.2497e-04, -8.0468e-04, -4.1526e-04,
          1.2534e-01,  2.8733e-02,  1.4620e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2526e-05,
          5.0267e-03, -2.9592e-04, -4.1757e-05,  4.3714e-02,  7.7562e-02,
          2.9869e-02,  9.6368e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])


Forward time:  0.01757335662841797
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  3.2476e-04, -2.3155e-05, -1.4006e-07,  6.8807e-04,
         -9.8982e-06,  4.7922e-03, -2.4401e-05,  5.4522e-03,  8.1189e-05,
          3.2475e-03, -1.7453e-04,  1.9871e-02, -5.7595e-05, -1.1498e-04,
          2.3314e-02,  1.0409e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0748e-04, -1.0243e-07, -8.3480e-05,  6.9420e-03,  1.6393e-03,
         -1.2292e-04,  1.8503e-02,  2.4335e-03,  8.0998e-03,  9.0325e-04,
         -2.4224e-05,  2.9262e-03,  4.5757e-02,  5.2620e-04, -1.1443e-04,
          9.7278e-03,  1.8014e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.1732e-03, -2.9636e-05, -1.4187e-05,  2.9315e-02, -6.2409e-05,
         -1.2827e-04,  1.4772e-02,  2.3541e-02, -1.4804e-06, -6.5311e-06,
         -8.6740e-05, -4.9213e-05,  1.8462e-04, -5.7966e-05,  4.4138e-02,
          5.2304e-02, -1.4194e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0297e-04,
          1.0469e-03, -7.0873e-05,  1.0431e-02,  1.9926e-02, -1.8480e-04,
          1.8135e-02,  4.0279e-02,  3.8567e-03,  1.7945e-03, -7.0380e-05,
          6.1347e-03,  2.2408e-02,  1.4110e-03, -4.5747e-04,  2.8645e-02,
          1.2694e-02, -7.8638e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4434e-04,  3.0121e-04,
         -6.3378e-05,  4.2903e-04,  1.6163e-02, -6.5335e-05, -1.9629e-04,
          4.8786e-02,  3.2624e-02, -9.6150e-05,  1.2904e-03, -2.7756e-06,
          1.7189e-02, -3.4389e-06, -1.2159e-04,  3.0720e-02,  3.1958e-02,
          8.3533e-03, -2.3551e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0121e-03, -2.1227e-05,
         -3.9182e-05,  1.2142e-02,  5.9476e-03,  2.5031e-03, -1.8827e-05,
          2.3074e-02, -7.0820e-05,  2.9900e-03, -1.2280e-04,  7.2066e-03,
          1.2441e-02,  7.8226e-03, -1.0195e-04,  3.2992e-02,  2.0228e-02,
         -1.0036e-04,  5.6124e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7036e-03, -6.8323e-05,
          1.0087e-02,  2.0036e-02,  5.7010e-03, -2.2798e-04,  4.4863e-02,
          2.0461e-02,  1.5747e-03, -9.0912e-05,  1.2240e-02,  2.8874e-02,
          3.8654e-05, -2.3393e-04,  3.5331e-02,  2.3113e-02, -4.0731e-05,
         -5.4627e-05,  2.2885e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7552e-03, -3.7683e-05,
          1.3379e-02, -2.9921e-05, -2.9662e-05,  1.0477e-02, -6.8524e-05,
          9.9989e-04, -8.0011e-05,  1.5604e-02,  2.2920e-02, -6.1054e-06,
         -2.7963e-05,  8.2808e-03,  3.2144e-02,  1.3438e-02, -1.5135e-04,
          2.8504e-03, -2.7784e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3610e-06, -7.9035e-05,
          2.7534e-02,  1.4674e-02, -8.0931e-05, -1.2768e-06,  3.8858e-02,
          5.0574e-03,  3.0624e-02,  7.1653e-03,  4.1746e-02,  1.1029e-02,
         -1.2624e-04,  4.4658e-02,  1.0709e-02, -9.9199e-05, -3.6969e-05,
         -2.0027e-05,  1.0195e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8681e-05, -4.5494e-05,
         -3.8812e-05, -1.1878e-04,  1.9076e-02,  4.5562e-02,  5.3924e-02,
          1.4856e-02,  3.0483e-02, -1.0647e-04, -1.0567e-04, -3.0335e-04,
          4.4510e-02,  9.1779e-03,  2.9138e-03, -2.4744e-05,  4.3852e-03,
         -8.4009e-06,  6.8268e-04],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0484e-04, -3.7474e-06,
          6.4221e-03, -3.8630e-05, -1.8713e-05, -9.6831e-05, -4.5777e-04,
         -2.0662e-04,  1.3703e-02,  1.3737e-02, -6.5408e-05,  2.5846e-03,
          7.5661e-03,  2.2836e-02, -9.7554e-05,  1.9443e-03, -7.0373e-05,
          2.0584e-03,  9.6107e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8265e-06,  3.5122e-03,
          7.0656e-03,  1.1214e-02, -8.4223e-05, -6.3677e-05,  1.7045e-03,
         -2.5443e-05, -1.6356e-04, -4.8375e-04, -3.1473e-04,  3.3630e-02,
          2.9652e-02, -6.5960e-05, -2.4554e-05, -1.0776e-04,  3.9022e-03,
          2.4236e-04,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.9429e-06, -2.3409e-05,
         -1.6916e-05,  5.7723e-03,  1.8342e-02,  1.8448e-02,  1.9315e-02,
          2.7612e-02,  2.6347e-02,  2.5435e-02,  6.1825e-02,  2.8886e-02,
         -7.4405e-05, -1.0072e-04, -3.5484e-05,  4.3999e-03,  4.5546e-04,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.9734e-06, -1.5541e-05,
          1.0140e-03, -2.1582e-05, -1.2997e-04,  6.5551e-03,  1.4791e-02,
          1.7632e-02, -1.3304e-04,  1.8620e-02,  1.4707e-02,  7.3450e-03,
         -1.4581e-04,  3.6605e-03, -2.6629e-05,  7.8925e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0552e-04,
         -8.3325e-06, -7.8394e-05,  7.3471e-03,  1.2735e-02, -1.2822e-05,
         -2.3025e-04,  7.2471e-03,  1.4615e-02,  1.9767e-02, -6.8949e-05,
          3.2320e-03, -9.8082e-05,  2.8073e-03,  7.9393e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9615e-05,  1.0722e-03,
         -5.1876e-05,  1.8707e-03,  7.7341e-03,  5.1293e-03, -8.8484e-05,
          8.8636e-03,  2.0506e-02,  1.6639e-02, -3.7179e-05, -4.9405e-05,
         -1.1576e-04,  5.4232e-03,  4.4293e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9869e-04,  1.2188e-04,
         -6.9384e-05,  1.0481e-02,  1.3217e-02, -3.6304e-05, -7.9006e-05,
          3.1144e-02,  1.4128e-02, -2.7015e-05, -8.4053e-05, -1.5721e-05,
          3.8132e-03,  7.1762e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  3.6084e-05,  1.7500e-03, -6.6773e-05,
          3.7587e-03,  2.5550e-02,  1.3651e-03, -1.7565e-04,  3.6599e-02,
          1.3933e-02, -4.3959e-06, -4.6934e-05,  3.1448e-03, -3.8718e-05,
          1.3797e-03,  2.0893e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  1.6057e-04,  3.0006e-03, -1.1184e-04,
          1.4239e-02, -3.4517e-05,  1.2879e-03, -5.9317e-05,  1.8612e-02,
          2.0364e-02, -1.8018e-05,  2.2800e-04, -9.9028e-05,  3.3642e-03,
          1.7550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.3128e-04,  3.6436e-03,  5.2701e-03,
          3.3342e-02,  6.6454e-03, -6.5492e-05,  3.0015e-02,  2.0732e-02,
          2.9801e-03, -4.4991e-05, -1.1458e-04,  4.8447e-03,  4.1368e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -1.2069e-06, -4.8512e-05, -1.3367e-04,
          2.0196e-03,  2.3727e-03, -5.0267e-05,  1.2572e-02,  1.4152e-02,
         -1.3111e-04, -4.7359e-05,  4.3129e-03,  5.3671e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -2.5901e-06, -2.0900e-05, -5.3669e-05,
          1.4086e-03, -6.4758e-05, -1.1111e-05,  1.9125e-03, -1.0002e-04,
          3.7343e-04, -1.0918e-05,  8.5120e-04,  1.2536e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00]])


















Forward time:  0.007519721984863281
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2717e-01,
          4.0219e-02, -2.3236e-04,  2.3859e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.3600e-02,  4.1662e-02, -2.1981e-04,  1.4565e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0900e-02,  2.5272e-01,
          1.7032e-01,  2.3872e-01,  2.1286e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7855e-02,
          1.6288e-01,  1.2766e-01,  6.8591e-02,  1.4232e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.8167e-03,  1.1279e-01,  4.8129e-02,
         -1.2544e-03,  1.3342e-01,  1.6876e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.4321e-02,
          1.7961e-01,  5.1010e-02,  2.0595e-01,  2.0364e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.3863e-02,  1.9274e-01,  1.2906e-02,
         -8.9223e-04,  1.0568e-01,  4.8241e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7250e-02,  1.5315e-01,
         -1.1584e-05, -1.3809e-03,  8.8352e-02,  4.1196e-02,  0.0000e+00,
          0.0000e+00,  1.8772e-02,  1.7236e-01,  8.4113e-02, -3.9078e-04,
          1.7320e-02,  1.3321e-01, -4.2065e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9378e-02,  1.6099e-01,  1.1219e-01,
         -3.7868e-04,  4.9846e-02,  1.6558e-01,  4.4804e-02,  0.0000e+00,
          4.8444e-03,  1.1895e-01,  1.2738e-01, -1.2749e-04, -8.8952e-04,
          5.1228e-02,  3.6061e-02, -7.4654e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  9.1601e-02,  2.0416e-01,  3.9240e-02,
         -3.1554e-04,  1.1966e-02,  3.1401e-02, -2.0841e-04,  0.0000e+00,
          5.1210e-02,  1.9101e-01,  3.7000e-02, -4.1415e-04, -1.1964e-05,
          8.4605e-02, -1.0887e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.5167e-01,  8.9318e-03, -3.3090e-04,
         -1.7116e-04,  7.9929e-02,  5.9826e-03,  8.5086e-03,  1.9970e-02,
          1.7126e-01,  6.6202e-02, -6.7818e-04, -6.6460e-04,  3.9016e-02,
         -2.0007e-04, -7.1543e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.4217e-02, -2.9920e-04,  5.1060e-02,
          2.0605e-01,  2.7236e-01,  1.9732e-01,  1.4778e-01,  1.3247e-01,
          1.9460e-01, -2.4695e-05, -5.7735e-04,  1.8313e-02,  1.8211e-03,
         -1.8041e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -1.2266e-03, -2.1061e-03, -8.6119e-04,
          1.9850e-01,  3.7629e-01,  4.2380e-01,  5.4257e-01,  4.8012e-01,
          2.9603e-01, -3.9939e-04, -1.4530e-04,  2.8193e-02, -3.3905e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -8.2072e-04, -2.6241e-03, -3.6059e-03,
         -3.4992e-03, -2.4430e-03, -1.5360e-03, -2.3479e-04, -8.7804e-04,
         -4.3883e-04, -6.2650e-04,  7.6560e-02, -3.1390e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5716e-04, -1.0435e-03,
         -2.2358e-03, -2.9590e-03, -9.5020e-04, -9.1918e-04, -9.7484e-04,
         -9.7103e-04,  5.5149e-02,  2.8209e-02, -5.9101e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.4222e-03,  1.1358e-01,  1.4865e-01, -1.5467e-05, -6.5995e-04,
         -8.6402e-05,  2.7592e-02, -3.2972e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6333e-03,
          9.7050e-02,  1.9012e-01,  5.8823e-02, -3.5955e-04, -5.0392e-04,
          5.1469e-02, -4.6226e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.1721e-02,
          2.0094e-01,  9.1892e-02,  1.3487e-02, -7.9387e-04,  4.8009e-02,
         -2.7134e-04, -1.5553e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2094e-02,  1.6733e-01,
          9.2133e-02, -2.2600e-04, -7.0128e-04,  2.3389e-02,  1.3328e-03,
         -1.3064e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  6.6611e-03,  1.3381e-01,  1.4105e-01,
         -1.0948e-04, -7.7166e-04, -2.1134e-04, -1.2738e-04, -3.0795e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  5.1490e-02,  1.7700e-01,  8.3662e-03,
         -9.3135e-04, -2.4589e-04,  1.3811e-02, -3.5636e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.8444e-03,  1.6017e-01,  6.0449e-02, -6.1923e-04,
         -5.8666e-04,  7.6501e-02, -3.1487e-04, -9.3317e-06,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0638e-02,  1.7186e-01, -1.8494e-04, -5.3188e-04,
          6.5871e-02,  8.1131e-02, -6.2211e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.5170e-05, -9.0845e-04, -2.0934e-03, -7.8778e-04,
          7.4480e-02, -3.0708e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -9.6042e-05, -1.9459e-03, -3.5577e-03, -2.6411e-03,
         -1.0001e-03, -1.2442e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]])
Forward time:  0.006430625915527344
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.9448e-02, -1.3394e-04,  1.6136e-02,
         -1.4403e-04, -3.0783e-04,  5.2576e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6680e-03, -1.7184e-05,
          3.3569e-03,  1.9148e-03, -2.9179e-04,  3.2096e-02,  0.0000e+00,
          0.0000e+00,  1.6670e-03,  6.7456e-02, -4.1188e-04,  8.9892e-02,
          5.7028e-02, -2.8801e-04,  4.0151e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.2601e-03,  3.0311e-02, -1.0512e-04,
          2.6662e-02,  3.4798e-02, -3.3606e-04,  5.1770e-02,  0.0000e+00,
          2.7783e-04,  1.9556e-02,  1.3003e-02, -3.6800e-04,  7.0696e-02,
          7.1244e-02, -1.8654e-04,  1.0146e-01,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1178e-02,  2.7758e-02, -2.4116e-04,
          6.0900e-02,  7.6189e-02, -2.3254e-04,  5.9739e-02,  0.0000e+00,
          1.0207e-02,  4.1603e-02, -1.1557e-03, -8.5520e-05,  5.5991e-02,
         -1.5406e-03,  1.4917e-02,  8.9662e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.1675e-03,  3.4479e-02, -4.9356e-04, -2.9308e-05,
          8.2434e-02, -6.6954e-04, -3.2382e-04,  1.2540e-01,  2.8709e-03,
          3.7919e-02, -1.6322e-04, -3.6447e-05, -1.3064e-05,  1.4402e-02,
         -9.9048e-04,  8.2713e-02,  4.9932e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.9635e-03,  2.7631e-02, -6.9050e-05, -6.6057e-04, -3.4294e-04,
          4.6258e-02, -1.4014e-03,  1.0149e-01,  2.8385e-02,  2.1843e-02,
          1.7339e-02, -7.9575e-04,  8.4963e-03,  5.1337e-02, -6.9329e-04,
         -2.5871e-04,  1.2232e-01,  2.2015e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.8707e-02,  3.8910e-02, -6.9797e-04,  1.7026e-02,  9.1902e-02,
         -9.4522e-04, -7.1750e-05,  7.7760e-02,  6.0233e-02,  4.2060e-02,
         -6.8824e-04,  1.5627e-02,  5.2962e-04, -1.5874e-04, -6.3030e-04,
          7.4411e-02,  6.8874e-02,  6.3377e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.0705e-02, -4.3294e-04,  8.7893e-03,  3.9081e-02, -2.1345e-04,
         -8.2222e-04,  1.6302e-02,  1.2080e-01,  4.0924e-02, -1.7906e-04,
         -3.2841e-04, -1.3381e-04,  3.2995e-02, -4.3431e-04, -1.6736e-04,
          1.1756e-01,  2.2878e-02,  1.7544e-03,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.2980e-02, -1.1591e-03,  4.6414e-02,  2.7363e-02,  1.7961e-02,
          3.4168e-02,  1.6246e-01,  4.4308e-02,  6.2808e-02, -1.1994e-03,
          2.4454e-02,  6.3542e-02, -3.6735e-04, -6.7487e-04,  1.0794e-01,
          4.7241e-02,  7.6849e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -3.2631e-04, -2.8178e-04, -5.7776e-06,  5.1969e-02,  5.0680e-02,
          9.1135e-02,  1.3176e-01,  9.2688e-02,  8.2152e-02, -1.3204e-04,
          7.8151e-02, -7.4141e-04, -4.4613e-04,  7.3638e-02,  8.8207e-02,
          1.1954e-02,  1.6813e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.2318e-04, -3.5642e-05, -9.3920e-05, -5.4906e-04, -1.4043e-03,
         -5.2258e-05,  1.2030e-01,  8.1644e-03,  3.7544e-02,  9.9969e-03,
          6.1229e-02, -2.3127e-04,  2.3573e-02,  1.2789e-01,  1.0794e-02,
          4.2398e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          5.7220e-03, -2.1177e-04, -2.5094e-04, -7.1029e-04, -5.7710e-04,
         -9.5490e-04, -1.7128e-03, -1.1766e-03, -9.8117e-04, -1.2676e-04,
          1.4999e-03, -4.4621e-04,  1.4483e-01,  2.0606e-02,  7.9680e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.7551e-03,  8.1386e-03,  2.3968e-02,  3.0003e-02,  1.8140e-02,
          8.4319e-02, -5.1004e-05,  1.6792e-02,  4.2339e-02, -1.8983e-04,
         -5.8791e-04,  8.8136e-02,  7.1404e-02,  1.1612e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  9.1056e-04,  5.3049e-03,  2.5947e-02,  6.8357e-02,
         -1.3603e-04,  1.5070e-02,  5.3581e-02, -2.5676e-04, -3.9307e-04,
          1.6322e-02,  1.2101e-01,  1.1201e-02,  1.3889e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0320e-02,  4.0767e-02, -2.1873e-04,
         -2.4565e-04,  2.6398e-02, -1.1196e-04,  3.5696e-03, -4.6947e-04,
          1.6014e-01,  1.4432e-02,  7.7487e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.9084e-03,  3.3718e-02, -5.7235e-05, -5.0851e-04,
         -4.5148e-06, -7.6340e-05,  2.9610e-02, -8.5378e-04,  1.3779e-01,
          3.3990e-02,  1.1978e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.0187e-03,  2.7009e-02,  1.0957e-02, -7.3123e-04, -1.2527e-04,
          1.9300e-02, -6.4409e-05, -9.0252e-04,  8.8378e-02,  7.6273e-02,
          1.4504e-02,  3.6550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          9.4895e-03,  3.9514e-02, -6.8865e-04,  1.2360e-02,  1.8741e-02,
         -4.0763e-04, -4.5876e-04,  5.6339e-02,  1.0900e-01,  1.1337e-02,
          3.0702e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4089e-04,
          3.4465e-02, -2.7877e-04, -2.9894e-04, -1.8016e-04,  5.4224e-02,
         -6.7833e-04,  3.4387e-02,  1.2917e-01,  1.2928e-02,  7.2370e-03,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8013e-03,
          4.5817e-02, -1.0638e-03,  4.9493e-02,  3.2880e-02, -4.1912e-04,
         -2.5154e-04,  1.5015e-01,  2.2694e-02,  9.0434e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4810e-04,
         -1.9305e-04, -8.3201e-04, -1.4927e-04,  5.9382e-02, -7.8189e-04,
          4.3681e-02,  8.4085e-02,  1.1117e-02,  2.1930e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3690e-05,
         -5.4588e-04, -3.5337e-05, -2.2497e-04, -8.0468e-04, -4.1526e-04,
          1.2534e-01,  2.8733e-02,  1.4620e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.2526e-05,
          5.0267e-03, -2.9592e-04, -4.1757e-05,  4.3714e-02,  7.7562e-02,
          2.9869e-02,  9.6368e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])
Forward time:  0.0054721832275390625
self.a[0]
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  3.2476e-04, -2.3155e-05, -1.4006e-07,  6.8807e-04,
         -9.8982e-06,  4.7922e-03, -2.4401e-05,  5.4522e-03,  8.1189e-05,
          3.2475e-03, -1.7453e-04,  1.9871e-02, -5.7595e-05, -1.1498e-04,
          2.3314e-02,  1.0409e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0748e-04, -1.0243e-07, -8.3480e-05,  6.9420e-03,  1.6393e-03,
         -1.2292e-04,  1.8503e-02,  2.4335e-03,  8.0998e-03,  9.0325e-04,
         -2.4224e-05,  2.9262e-03,  4.5757e-02,  5.2620e-04, -1.1443e-04,
          9.7278e-03,  1.8014e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.1732e-03, -2.9636e-05, -1.4187e-05,  2.9315e-02, -6.2409e-05,
         -1.2827e-04,  1.4772e-02,  2.3541e-02, -1.4804e-06, -6.5311e-06,
         -8.6740e-05, -4.9213e-05,  1.8462e-04, -5.7966e-05,  4.4138e-02,
          5.2304e-02, -1.4194e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0297e-04,
          1.0469e-03, -7.0873e-05,  1.0431e-02,  1.9926e-02, -1.8480e-04,
          1.8135e-02,  4.0279e-02,  3.8567e-03,  1.7945e-03, -7.0380e-05,
          6.1347e-03,  2.2408e-02,  1.4110e-03, -4.5747e-04,  2.8645e-02,
          1.2694e-02, -7.8638e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4434e-04,  3.0121e-04,
         -6.3378e-05,  4.2903e-04,  1.6163e-02, -6.5335e-05, -1.9629e-04,
          4.8786e-02,  3.2624e-02, -9.6150e-05,  1.2904e-03, -2.7756e-06,
          1.7189e-02, -3.4389e-06, -1.2159e-04,  3.0720e-02,  3.1958e-02,
          8.3533e-03, -2.3551e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0121e-03, -2.1227e-05,
         -3.9182e-05,  1.2142e-02,  5.9476e-03,  2.5031e-03, -1.8827e-05,
          2.3074e-02, -7.0820e-05,  2.9900e-03, -1.2280e-04,  7.2066e-03,
          1.2441e-02,  7.8226e-03, -1.0195e-04,  3.2992e-02,  2.0228e-02,
         -1.0036e-04,  5.6124e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7036e-03, -6.8323e-05,
          1.0087e-02,  2.0036e-02,  5.7010e-03, -2.2798e-04,  4.4863e-02,
          2.0461e-02,  1.5747e-03, -9.0912e-05,  1.2240e-02,  2.8874e-02,
          3.8654e-05, -2.3393e-04,  3.5331e-02,  2.3113e-02, -4.0731e-05,
         -5.4627e-05,  2.2885e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7552e-03, -3.7683e-05,
          1.3379e-02, -2.9921e-05, -2.9662e-05,  1.0477e-02, -6.8524e-05,
          9.9989e-04, -8.0011e-05,  1.5604e-02,  2.2920e-02, -6.1054e-06,
         -2.7963e-05,  8.2808e-03,  3.2144e-02,  1.3438e-02, -1.5135e-04,
          2.8504e-03, -2.7784e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3610e-06, -7.9035e-05,
          2.7534e-02,  1.4674e-02, -8.0931e-05, -1.2768e-06,  3.8858e-02,
          5.0574e-03,  3.0624e-02,  7.1653e-03,  4.1746e-02,  1.1029e-02,
         -1.2624e-04,  4.4658e-02,  1.0709e-02, -9.9199e-05, -3.6969e-05,
         -2.0027e-05,  1.0195e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8681e-05, -4.5494e-05,
         -3.8812e-05, -1.1878e-04,  1.9076e-02,  4.5562e-02,  5.3924e-02,
          1.4856e-02,  3.0483e-02, -1.0647e-04, -1.0567e-04, -3.0335e-04,
          4.4510e-02,  9.1779e-03,  2.9138e-03, -2.4744e-05,  4.3852e-03,
         -8.4009e-06,  6.8268e-04],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0484e-04, -3.7474e-06,
          6.4221e-03, -3.8630e-05, -1.8713e-05, -9.6831e-05, -4.5777e-04,
         -2.0662e-04,  1.3703e-02,  1.3737e-02, -6.5408e-05,  2.5846e-03,
          7.5661e-03,  2.2836e-02, -9.7554e-05,  1.9443e-03, -7.0373e-05,
          2.0584e-03,  9.6107e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8265e-06,  3.5122e-03,
          7.0656e-03,  1.1214e-02, -8.4223e-05, -6.3677e-05,  1.7045e-03,
         -2.5443e-05, -1.6356e-04, -4.8375e-04, -3.1473e-04,  3.3630e-02,
          2.9652e-02, -6.5960e-05, -2.4554e-05, -1.0776e-04,  3.9022e-03,
          2.4236e-04,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.9429e-06, -2.3409e-05,
         -1.6916e-05,  5.7723e-03,  1.8342e-02,  1.8448e-02,  1.9315e-02,
          2.7612e-02,  2.6347e-02,  2.5435e-02,  6.1825e-02,  2.8886e-02,
         -7.4405e-05, -1.0072e-04, -3.5484e-05,  4.3999e-03,  4.5546e-04,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.9734e-06, -1.5541e-05,
          1.0140e-03, -2.1582e-05, -1.2997e-04,  6.5551e-03,  1.4791e-02,
          1.7632e-02, -1.3304e-04,  1.8620e-02,  1.4707e-02,  7.3450e-03,
         -1.4581e-04,  3.6605e-03, -2.6629e-05,  7.8925e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0552e-04,
         -8.3325e-06, -7.8394e-05,  7.3471e-03,  1.2735e-02, -1.2822e-05,
         -2.3025e-04,  7.2471e-03,  1.4615e-02,  1.9767e-02, -6.8949e-05,
          3.2320e-03, -9.8082e-05,  2.8073e-03,  7.9393e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9615e-05,  1.0722e-03,
         -5.1876e-05,  1.8707e-03,  7.7341e-03,  5.1293e-03, -8.8484e-05,
          8.8636e-03,  2.0506e-02,  1.6639e-02, -3.7179e-05, -4.9405e-05,
         -1.1576e-04,  5.4232e-03,  4.4293e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9869e-04,  1.2188e-04,
         -6.9384e-05,  1.0481e-02,  1.3217e-02, -3.6304e-05, -7.9006e-05,
          3.1144e-02,  1.4128e-02, -2.7015e-05, -8.4053e-05, -1.5721e-05,
          3.8132e-03,  7.1762e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  3.6084e-05,  1.7500e-03, -6.6773e-05,
          3.7587e-03,  2.5550e-02,  1.3651e-03, -1.7565e-04,  3.6599e-02,
          1.3933e-02, -4.3959e-06, -4.6934e-05,  3.1448e-03, -3.8718e-05,
          1.3797e-03,  2.0893e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  1.6057e-04,  3.0006e-03, -1.1184e-04,
          1.4239e-02, -3.4517e-05,  1.2879e-03, -5.9317e-05,  1.8612e-02,
          2.0364e-02, -1.8018e-05,  2.2800e-04, -9.9028e-05,  3.3642e-03,
          1.7550e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.3128e-04,  3.6436e-03,  5.2701e-03,
          3.3342e-02,  6.6454e-03, -6.5492e-05,  3.0015e-02,  2.0732e-02,
          2.9801e-03, -4.4991e-05, -1.1458e-04,  4.8447e-03,  4.1368e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -1.2069e-06, -4.8512e-05, -1.3367e-04,
          2.0196e-03,  2.3727e-03, -5.0267e-05,  1.2572e-02,  1.4152e-02,
         -1.3111e-04, -4.7359e-05,  4.3129e-03,  5.3671e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -2.5901e-06, -2.0900e-05, -5.3669e-05,
          1.4086e-03, -6.4758e-05, -1.1111e-05,  1.9125e-03, -1.0002e-04,
          3.7343e-04, -1.0918e-05,  8.5120e-04,  1.2536e-05,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00]])












Попробовать поварировать batch size и также нужно обічную нейронку попробовать улучшить чтоб понять что при таких то данніх мі больше віжать из нее не можем и тогда нужно будет улучшать конв нейронку


